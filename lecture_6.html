<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="NRES 710" />


<title>Linear Regression (cont.)</title>

<script src="site_libs/header-attrs-2.27/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 710</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Syllabus</a>
</li>
<li>
  <a href="schedule.html">Schedule</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lecture_1.html">Syllabus and the Purpose of Statistics</a>
    </li>
    <li>
      <a href="lecture_2.html">P-value discussion and Intro to R</a>
    </li>
    <li>
      <a href="lecture_3.html">Sampling uncertainty</a>
    </li>
    <li>
      <a href="lecture_4.html">Linear regression</a>
    </li>
    <li>
      <a href="LECTURE3.html">Taxonomy of common statistics</a>
    </li>
    <li>
      <a href="LECTURE4.html">t-test and z-test</a>
    </li>
    <li>
      <a href="LECTURE5.html">chi-squared tests</a>
    </li>
    <li>
      <a href="LECTURE6.html">Linear Regression</a>
    </li>
    <li>
      <a href="LECTURE7.html">ANOVA</a>
    </li>
    <li>
      <a href="LECTURE8.html">GLM</a>
    </li>
    <li>
      <a href="LECTURE9.html">GLMM</a>
    </li>
    <li>
      <a href="LECTURE10.html">Machine Learning</a>
    </li>
    <li>
      <a href="GIT_tutorial.html">Intro to GIT</a>
    </li>
    <li>
      <a href="LECTURE11.html">Next steps</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="EXERCISE1.html">Exercise 1 - Data Summary Functions</a>
    </li>
    <li>
      <a href="EXERCISE2.html">Exercise 2 - t-tests</a>
    </li>
    <li>
      <a href="EXERCISE3.html">Exercise 3 - Simple Linear Regression</a>
    </li>
    <li>
      <a href="EXERCISE4.html">Exercise 4 - Multiple Linear Regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    More Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Links.html">Links</a>
    </li>
    <li>
      <a href="FINALPROJ.html">Final Projects</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Linear Regression (cont.)</h1>
<h4 class="author">NRES 710</h4>
<h4 class="date">Last compiled: 2024-07-29</h4>

</div>


<div id="review" class="section level2">
<h2>Review</h2>
<p>This week we will continue to explore linear regression by talking
about <strong>assumptions of regression</strong> – and in fact these are
important assumptions of many other statistical tests. And then we will
discuss how to use linear regression models to make
<strong>predictions</strong>.</p>
<p><strong>Most important thing we have learned so far</strong>:</p>
<ul>
<li><span class="math inline">\(Y_i = \beta_0 + \beta_1x_i + \epsilon
\sim N(0, \sigma)\)</span></li>
</ul>
<p>There are many assumptions that this regression test makes! But we
will focus on what are considered the five most important of these
assumptions.</p>
</div>
<div id="assumptions" class="section level2">
<h2>Assumptions</h2>
<p>What are the assumptions of statistical test and how do they
influence your results?</p>
<p>The first thing you need to know about assumptions of statistical
tests (regression, t-test, ANOVA, other tests we will cover…) is that
the tests are <strong>robust to violations of assumptions</strong>.</p>
<ul>
<li>Robust means that: if an assumption is violated, it very rarely
influences the results we get from the analysis (e.g., slope).</li>
<li>We’ll talk about which of the assumptions influence different
parameters…</li>
<li>But for most parameters, if the assumptions are violated it does not
influence the slope.</li>
<li>Assumption violation may influence the standard deviation, but this
is not often reported.</li>
<li><strong>Violations cause the p-value to increase.</strong> This
means that violations are likely to be conservative. Since we want to
avoid committing Type I error (rejecting the null when in fact it is
true), then if assumption violation causes p-values to increase then we
are less likely to commit Type I error.</li>
</ul>
<p>A general rule (<em>axiom</em>) in statistics is that: <strong>the
more assumptions a test makes, the more powerful it is (power =
p-values).</strong></p>
<p>We often use statistical tests that make assumptions. Often, these
assumptions are true. And since we make more assumptions, we are more
likely to detect a significant effect. <strong>If these assumptions are
valid.</strong></p>
<p>I often don’t care too much about assumptions – because they are
often met due to our <strong>study design</strong>, the specific
analysis we chose, and <strong>most analyses are robust to violations of
assumptions</strong>. But, <strong>reviewers do</strong>. Reviewers will
try to find something wrong with your paper. They will try to find
something wrong and jam up the process. So it can be useful to carefully
document how you examined for violations of assumptions in your
analysis. This gets tedious, but is part of the ‘statistical ritual’ of
our field… (Or maybe it shouldn’t be. Johnson [1999] made suggestions
that our statistical ritual leads to bad practices, and we will read
another paper to this effect at the end of the semester.)</p>
<p>But as for me, again, I don’t care too much about these assumptions,
because <strong>most analyses are robust to violations of
assumptions</strong>.</p>
</div>
<div id="five-regression-assumptions" class="section level2">
<h2>Five regression assumptions</h2>
<p>There are <strong>5 assumptions</strong> to linear regression. I put
the equation up on the board again because most of these assumptions are
indicated in the equation, either explicitly or implicitly.</p>
<div id="continuous-y" class="section level3">
<h3>Continuous Y</h3>
<ul>
<li><p>Should be continuous; not a count, like a number. But… if it is a
count, that’s potentially okay, because regression/ANOVA are robust to
violations of assumptions. We don’t really need a test for this – if you
collected the data, you should know whether it is continuous or
not!</p></li>
<li><p>Note: linear regression also assumes that your X-variable is
continuous… but we can relax this assumption, and we will do so next
week when we explore t-tests! More on this soon.</p></li>
<li><p>If you Y is not continuous, it will not influence your slope, but
it might increase your p-value.</p></li>
</ul>
</div>
<div id="error-is-normally-distributed" class="section level3">
<h3>Error is normally distributed</h3>
<ul>
<li>Very clearly indicated in the equation! Important and something that
a lot of people get wrong. Some folks say that X-variable has to be
normally distributed, continuous, etc. – but nope. Others assume that
your Y-variable has to be normally distributed. Nope! This assumption
relates to the <strong>error</strong> around the Y-variable.</li>
</ul>
<p>For example: consider the data in the left graph. There is a gap in
values for the middle-range of X-values. If we examine this as a
frequency histogram (middle graph), this is not a normally-distributed
y-variable; it is bimodally distributed! This is okay. When we run this
regression, we have not violated any assumptions, because the error is
normally distributed around the line.</p>
<p><img src="lecture_6_files/figure-html/example-1-1.png" width="576" /><img src="lecture_6_files/figure-html/example-1-2.png" width="576" /></p>
<p>Then why are people always asking if the Y-variable is normally
distributed…? This is because if you look at the distribution of the
y-data and it appears normal, the residuals will almost always be normal
when you run the analysis.</p>
<p>But, if you run a histogram and your y-data are not normal, this does
not necessarily mean that your error will also not be normal. To really
know if the assumption is violated, you need to run the regression and
examine whether the residuals are normal (third graph).</p>
<p>If your error is not normally distributed, it’s not going to
influence your slope – but it might increase your p-values a little
bit.</p>
</div>
<div id="linear-relationship-between-x-and-y" class="section level3">
<h3>Linear relationship between X and Y</h3>
<p>This one is important. This is implicit in our linear model
equation.</p>
<p>It assumes that there is a single parameter – the slope – describing
the relationship between X and Y.</p>
<p>The reason why I think this is important is because so often in
ecology/natural resource management I see people obtaining two
continuous variables and immediately running a regression model –
without ever considering whether their data have a linear relationship.
They don’t even think about it.</p>
<p>This is a problem, because in ecology… many processes of interest are
non-linear!</p>
<p>Example: mesocosm experiment. We want to understand the effect of
crayfish predators on prey fish. Does fish abundance decrease and
predatory crayfish increases?</p>
<p><img src="lecture_6_files/figure-html/predator-prey-simulation-1.png" width="768" /></p>
<p>This very clearly violates the assumption of linearity! We can fit a
better statistical model – one that does not assume linearity – which
can better help us measure this relationship and explain it to the
scientific community!</p>
<p>So, don’t assume there is a linear relationship between X and Y –
examine this, verify, and adjust your model as needed.</p>
<p>If the relationship is not linear, <strong>this will alter your
slope</strong>! We are measuring something that is not linear an</p>
</div>
<div id="homoscedasticity" class="section level3">
<h3>Homoscedasticity</h3>
<p><em>homo</em> = same; <em>scedasticity</em> = variance, noise, error,
etc.</p>
<p>Implicit in our equation: - <span class="math inline">\(\epsilon \sim
N(0, \sigma)\)</span></p>
<p>Constant variance: <em>error does not change not matter what the X
and Y values are.</em></p>
<p><img src="lecture_6_files/figure-html/example-3-1.png" width="576" /></p>
<p>We can visualize homoscedasticity by imagining/drawing normally
distributed bell curves amidst our data along the regression line…</p>
<p>An example of <strong>heteroscedasticity</strong> is any case where
your variance changes. This commonly occurs in ecology when we count
animals. For example, when we are electofishing for fish in a river,
areas with no fish have little variance; areas with many fish have high
variance! It creates this cone-shaped data.</p>
<p><img src="lecture_6_files/figure-html/example-4-1.png" width="576" /></p>
<p>We can visualize <em>heteroscedasticity</em> by imagining/drawing
normally distributed bell curves amidst our data along the regression
line, and the bell curves get wider as we increase along X.</p>
<p><em>Heteroscedasticity</em> could also happen in a non-linear
way.</p>
<p><strong>Q:</strong> Will heteroscedasticity influence your slope?
No.</p>
<p>We can account for <em>heteroscedasticity</em> in our model by adding
a weighting paramter to the error component: <span
class="math inline">\(\epsilon \sim N(0, \sigma * y)\)</span> would
allow for error to increase with <span
class="math inline">\(y\)</span>!</p>
</div>
<div id="independent-samples" class="section level3">
<h3>Independent samples</h3>
<p>When people say that the x-variable is the ‘independent variable’,
this is what they really mean! Your samples should be independent of
eachother and there should be <strong>no autocorrelation</strong>.</p>
<p>Example: measuring pollution in water samples every 10 m down the
middle of a river from a chemical plant. These data will have
autocorrelation, because pollution can’t change that much from sample to
sample.</p>
<p><strong>Q:</strong> How might you eliminate or minimize
autocorrelation? Maybe by increasing distance between samples – measure
every kilometer. This decreases autocorrelation, but also decreases
sample size. Tradeoff…</p>
<p>I personally don’t worry too much about autocorrelation, because
often when you fix it/account for it, nothing changes. If you had a
strong slope and p-value with one test, you will likely get a strong
slope and p-value with another test.</p>
<p>Consider these autocorrelated data:</p>
<p><img src="lecture_6_files/figure-html/example-5-1.png" width="576" /></p>
<p>Instead of our points bouncing around the line, they tend to follow
eachother.</p>
<p>This will not affect our slope, and it probably won’t affect the
p-value too much (would only increase). So again, linear regression is
robust to violation of this assumption.</p>
<p>Two types of autocorrelation issues: spatial and temporal
autocorrelation. We will discuss how to deal with this down the road.
But again, it’s not too big of a concern.</p>
<p>Many things are autocorrelated in nature. Animal movements, for
example! Is this a problem?</p>
<p>Maybe not. This is what animals do – they move! Try to get big sample
sizes.</p>
</div>
</div>
<div id="evaluating-assumptions-w-graphs" class="section level2">
<h2>Evaluating assumptions w/ graphs</h2>
<p>Statistical tests exist to statistically test for these assumptions.
These are p-value generating tests. There are some consequences of
this.</p>
<ul>
<li>If you have a small sample size, the assumption will never be
violated! Because of the relationship between sample size and p-values
that we have identified in previous classes.</li>
<li>Conversely, if you have a really large sample, the assumption will
always be violated!</li>
</ul>
<p>So, for these reasons, I don’t like these tests, and I don’t
recommend using these tests.</p>
<p>Instead, what I do I look at my data graphically! And I will teach
you to do this also. We will visually examine our data to identify
whether our data meet these assumptions or not. If it has been violated,
we will see this. If we can see the assumption has been violated, then
we now know this.</p>
<p>Useful rule of thumb:</p>
<ul>
<li>If you can’t see it, it doesn’t exist, and you assume there isn’t
one.</li>
<li>If you can see it, then an assumption may be violated, and then it’s
our decision to do something about it or not.</li>
</ul>
<p>We have four main assumptions, and we will use four graphical
approaches to examine whether these assumptions are met.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Assumption
</th>
<th style="text-align:left;">
X-Y Scatterplot
</th>
<th style="text-align:left;">
Residuals Scatterplot
</th>
<th style="text-align:left;">
Histogram of Residuals
</th>
<th style="text-align:left;">
Autocorrelation Function (ACF)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Normality
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Linearity
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Homoscedasticity
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
No autocorrelation
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
<div id="x-y-scatterplots" class="section level3">
<h3>X-Y Scatterplots</h3>
<p>This first graph shows data where <strong>none of the assumptions are
violated</strong>.</p>
<p><img src="lecture_6_files/figure-html/no-violations-1.png" width="432" /></p>
<ul>
<li>Data are very clearly linear.</li>
<li>Data appear to be normally distributed around the line. Most are
close to the line, but some are out in the tails.</li>
<li>Does not appear to be any autocorrelation.</li>
<li>Does not appear to be any heteroscedasticity.</li>
</ul>
<p><strong>This is how your data should look!</strong></p>
<p>This second graph shows data were the assumption of error normality
is violated.</p>
<p><img src="lecture_6_files/figure-html/error-violated-1.png" width="432" /></p>
<p>We can see that normality is violated because there are no tails
below the line!</p>
<p><strong>Q:</strong> Has this influenced the slope? No. It would
influence the intercept (but nobody reports that ever, so no big
deal).</p>
<p>This third graph shows data where the assumption of
<strong>linearity</strong> is violated.</p>
<p><img src="lecture_6_files/figure-html/nonlinear-1.png" width="432" /></p>
<ul>
<li>A linear regression model would not fit these data well, so we would
want to seek an alternative approach.</li>
<li>Note: Some might say that these data are not normally distributed,
but it is. Most points are centered on the line, with some out on the
tails.</li>
</ul>
<p>This fourth graph shows data where the assumption of
<strong>homoscedasticity</strong> is violated.</p>
<p><img src="lecture_6_files/figure-html/heteroscedasticity-1.png" width="432" /></p>
<p>These data are <strong>heteroscedastic</strong>; as X increases,
error increases.</p>
<p>We don’t need a statistical test to know that these data are
heteroscedastic.</p>
<p>This last graph shows when the data are not independent and
autocorrelation is present in the data.</p>
<p><img src="lecture_6_files/figure-html/autocorrelation-1.png" width="432" /></p>
<pre><code>##           x       error         y
## 10 1.111354  2.21685996  7.439568
## 11 1.218993  2.59649944  8.034485
## 12 1.275317  2.09417599  7.644809
## 13 1.306957  1.76096861  7.374882
## 14 1.388061  0.74239323  6.518514
## 15 1.428000 -0.32939800  5.526602
## 16 1.471136 -0.02586936  5.916404
## 17 1.524447  0.42234042  6.471235
## 18 1.750527  0.47534465  6.976398
## 19 1.876911  1.39761211  8.151434
## 20 2.065314  3.44769680 10.578325</code></pre>
<p>What do we see here…?</p>
<ul>
<li>The errors are similar to each other; i.e., they are correlated to
one another.</li>
<li>The error is not centered on the line, but rather <em>follows
itself</em>.</li>
<li>Two types of autocorrelation; we’ll discuss this in a future lecture
when discuss how to fix or model autocorrelation (which requires more
complicated models, no ready for this just yet).</li>
</ul>
</div>
<div id="residuals-scatterplot" class="section level3">
<h3>Residuals Scatterplot</h3>
<p>Residuals scatterplot involve making a graph of:</p>
<ul>
<li><strong>X-variable –&gt; X data</strong></li>
<li><strong>Y-variable –&gt; residual (error)</strong></li>
</ul>
<p><img src="lecture_6_files/figure-html/residual_plot-1.png" width="864" /></p>
<p>Assuming we had a pretty usual data with X and Y and we fit a
regression line (above), we can revisualize that graph with the same
X-variable but now with the residuals of Y on the y-axis. We sort of
flip that graph, make the regression line be at 0, and then residuals
above and below that line are visualized with the Y-variable. This is a
‘residuals plot’.</p>
<p>For example, the residuals plot can be useful when you have a large
range of X and Y, and your error is very small:</p>
<p><img src="lecture_6_files/figure-html/residual_plot_2-1.png" width="864" /></p>
<p>The data look pretty tight around the line in the X-Y scatterplot,
but when we look at the residual plot, we see something else. This is
common when we have low error – small noise.</p>
<p><strong>Q:</strong> What is happening here – what assumption has been
violated?</p>
<p><strong>Residuals scatterplots</strong> are useful for all four of
these assumptions. Here are the four simulated datasets we used for X-Y
scatterplots but not visualized using residual scatterplots:</p>
<p><img src="lecture_6_files/figure-html/residual_plot_examples-1.png" width="864" /></p>
</div>
<div id="histogram-of-residuals" class="section level3">
<h3>Histogram of Residuals</h3>
<p>This is a way to look at the residuals from a global perspective, so
it is most useful for looking at normality. Not useful for the others.
You can see heteroscedasticity with it (kirtosis), but most useful for
checking for normality.</p>
<p><img src="lecture_6_files/figure-html/histogram_of_residuals-1.png" width="864" /></p>
</div>
<div id="autocorrelation-function-acf" class="section level3">
<h3>Autocorrelation Function (ACF)</h3>
<p>The autocorrelation function (<strong>ACF</strong>) shows us the
correlation for the residuals. It teaches us about the probability
that:</p>
<ul>
<li>If one point is above the line, what is the chance that the next
point will also be above the line?</li>
<li>Alternatively, if another point is below the line, what is the
chance that the next point will also be below the line?</li>
</ul>
<p>As you might expect, it is best for teaching us whether our data are
<strong>autocorrelated</strong>.</p>
<p>The autocorrelation function, specifically, measures how similar each
datapoint is to the other datapoints that are behind it in the
dataframe. It compares residuals at different lags in the dataframe. At
a lag of zero, we expect high correlation, because we compare each point
to itself. At lags of 1 or more, if there is autocorrelation, then the
ACF metric will be high and positive (&gt; 0.2) when comparing each a
datapoint to points lagged behind it (i.e., high correlation to nearby
data in the dataset). If there is no autocorrelation, then the ACF
metric will randomly be positive and negative and usually within 0.2 of
0.</p>
<p>Here’s an example using (1) our simulated data that meet all of the
assumptions, and (2) the autocorrelated data from above:</p>
<p><img src="lecture_6_files/figure-html/autocorrelation_function-1.png" width="864" /></p>
<p>The autocorrelation function can also be useful for
<strong>non-linearity</strong>. For example:</p>
<p><img src="lecture_6_files/figure-html/nonlinear_2-1.png" width="864" /></p>
<p>These data are non-linear – and were simulated with no
autocorrelation. Data on the left and right regions of the graph are
below the line, whereas the middle-most X-data are above the line.</p>
<p>These data are not autocorrelated, but the <em>residuals</em> show
evidence of autocorrelation. When we create an ACF plot, it suggests
autocorrelation, but this isn’t the case. It is due to the
non-linearity. (If we fixed the non-linearity issue, the residual
autocorrelation would go away.)</p>
<p>So, if we use an ACF and it shows autocorrelation, we should make
sure we don’t have a non-linearity issue.</p>
</div>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Assumption
</th>
<th style="text-align:left;">
X-Y Scatterplot
</th>
<th style="text-align:left;">
Residuals Scatterplot
</th>
<th style="text-align:left;">
Histogram of Residuals
</th>
<th style="text-align:left;">
Autocorrelation Function (ACF)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Normality
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Linearity
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
**
</td>
</tr>
<tr>
<td style="text-align:left;">
Homoscedasticity
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
No autocorrelation
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
!!
</td>
</tr>
</tbody>
</table>
<p><a href="lecture_7.html">–go to next lecture–</a></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
