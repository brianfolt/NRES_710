<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="NRES 710" />


<title>Generalized Linear Mixed Models (GLMM)</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 710</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="schedule.html">Schedule</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="INTRO.html">Introduction to NRES 710</a>
    </li>
    <li>
      <a href="LECTURE1.html">Basic Concepts</a>
    </li>
    <li>
      <a href="LECTURE2.html">Sampling uncertainty</a>
    </li>
    <li>
      <a href="LECTURE3.html">Taxonomy of common statistics</a>
    </li>
    <li>
      <a href="LECTURE4.html">t-test and z-test</a>
    </li>
    <li>
      <a href="LECTURE5.html">chi-squared tests</a>
    </li>
    <li>
      <a href="LECTURE6.html">Linear Regression</a>
    </li>
    <li>
      <a href="LECTURE7.html">ANOVA</a>
    </li>
    <li>
      <a href="LECTURE8.html">GLM</a>
    </li>
    <li>
      <a href="LECTURE9.html">GLMM</a>
    </li>
    <li>
      <a href="LECTURE10.html">Next steps</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="EXERCISE1.html">Exercise- data summary functions</a>
    </li>
    <li>
      <a href="EXERCISE2.html">Exercise- t-tests</a>
    </li>
    <li>
      <a href="EXERCISE3.html">Exercise- simple linear regression</a>
    </li>
    <li>
      <a href="EXERCISE4.html">Exercise- multiple linear regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    More Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Links.html">Links</a>
    </li>
    <li>
      <a href="FINALPROJ.html">Final Projects</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Datasets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Data1.dat">Data1</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Generalized Linear Mixed Models (GLMM)</h1>
<h4 class="author">NRES 710</h4>
<h4 class="date">Fall 2022</h4>

</div>


<div id="download-the-r-code-for-this-lecture" class="section level2">
<h2>Download the R code for this lecture!</h2>
<p>To follow along with the R-based lessons and demos, <a
href="LECTURE9.R">right (or command) click on this link and save the
script to your working directory</a></p>
<p>NOTE: Ben Bolker maintains a very useful “FAQ” site on GLMM: if you
are using GLMMs I encourage you to read through it and run through the R
examples: <a
href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html">https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html</a></p>
</div>
<div id="overview-mixed-effects-models" class="section level2">
<h2>Overview: Mixed-effects models</h2>
<p>Remember the assumption of independent observations? Every single one
of the models we have considered so far makes that assumption. If that
assumption is violated, we are committing pseudoreplication. If
pseudoreplication is relatively minor we may be able to ignore it for
modeling (but still reporting the potential issue). But in many cases
the issue is too large to ignore.<br />
Mixed models allow us to build more realistic models that incorporate
some known potential sources of non-independence in our data.</p>
<p>The term <strong>mixed-effects models</strong> refers to the fact
that these models have two kinds of predictor variables: <em>fixed
effects</em> and <em>random effects</em>. The random effects are what
allow us to incorporate potential inter-dependencies among our
observations.</p>
<div id="is-it-a-fixed-effect-or-a-random-effect"
class="section level3">
<h3>Is it a fixed effect or a random effect?</h3>
<p>One point of confusion that quickly bubbles up around mixed-effects
models is the question of whether you should include a predictor
variable as a random or a fixed effect.</p>
<p>It might help to consider some typical random effects and some
typical fixed effects:</p>
<div id="fixed-effects" class="section level4">
<h4>Fixed effects</h4>
<p>Typical fixed effects include:</p>
<ul>
<li>Temperature (continuous fixed effect- e.g., linear regression)</li>
<li>Treatment (categorical fixed effect- e.g., ANOVA)</li>
<li>Interaction between temperature and treatment (interaction fixed
effect)</li>
</ul>
<p>Fixed effects are what we have been calling ‘predictor variables’ in
this class. They usually represent the variables that we want to relate
to our response variable. Ideally, our observations span the full range
of our fixed effects (predictor variables) such that we can use our data
to make inference about the relationship between our response and
predictor variables across the range of values that we might encounter
in our entire population of interest.</p>
<p>There is no assumption that our predictor variables are normally
distributed- in fact, the only assumption we make about the predictor
variables (usually) are that (1) they are measured with certainty and
(2) we ideally want them to be distributed evenly across the range of
values across which we want to make inference about our response
process.</p>
<p>For example, if we want to make inference about the relationship
between tree diameter and volume, we would like to take measurements of
trees that vary from the smallest-diameter trees we wish to make
inference about to the largest-diameter trees that we’d like to make
inference about. To ensure that our sample includes the full range of
diameters, we might specifically select trees that cover the entire
range of interest. That is, we could <strong>fix</strong> the set of
trees in our samples to include the full range of our predictor
variable. There is no rule stating that we have to select our predictor
variable levels from a random process. In fact, experimental design is
all about pre-determining our predictor variable levels!</p>
<p>The term <strong>fixed effect</strong> comes from experimental
design, where we literally arrange (fix) our observations into specific
treatment and control groups. For example, we might take 100 otherwise
interchangeable sapling trees and subject them randomly to different
treatments of <strong>fixed</strong> levels of some factor that might
influence growth (say nitrogen concentrations)- and then we can make
inference about the effect of nitrogen across the range of
concentrations that we determined.</p>
<p><strong>SIDE NOTE</strong>: we can (and often do) make inferences
about our response variable for levels of our predictor variables that
are outside the range of values in our data set. This is called
<strong>extrapolation</strong> and can be a dangerous practice because
we lack empirical support for this type of inference, especially when
the predictions are far outside the bounds of our data set.</p>
</div>
<div id="random-effects" class="section level4">
<h4>Random effects</h4>
<p>Typical Random effects include:</p>
<ul>
<li>Block ID (blocks are a small subset of the units about which you
want to make inference, multiple observations per block)</li>
<li>Site ID (sites are a small subset of the units about which you want
to make inference, multiple observations per site)</li>
<li>Year (study years are a small subset of the years about which you
want to make inference, multiple observations per year)</li>
<li>Individual (individuals studied are randomly selected from the
population of interest, each individual subjected to repeated
measurements)</li>
</ul>
<p>First of all, random effects (in the context of standard GLMM [and
this course] anyway) should be categorical- and should have multiple
categories (usually &gt;5 and ideally much larger).</p>
<p>Second, random effects should represent a random sample or otherwise
a subset of the units about which you want to make inference.</p>
<p>Third, random effects variables should have multiple observations per
level (category)- at least for most levels. If you only have one
observation per level, it is not a random effect- it’s just a replicate
observation!</p>
<p>Typically, we assume that random effects are normally distributed:
i.e., described by a mean and a variance (or std dev).</p>
</div>
</div>
<div id="mixed-effects-models-in-regression-notation"
class="section level3">
<h3>Mixed effects models in regression notation</h3>
<p>Before we run examples in R, let’s look at linear mixed-effects
regression models in regression notation.</p>
<p>The equation should look familiar- the only difference is that there
is more than one error term. Each random effect is now associated with a
new error term…</p>
<p>Let’s say we are fitting the following mixed-effects model:</p>
<p><strong>Response variable:</strong> Tortoise clutch size<br />
<strong>Predictor variables: fixed effects:</strong> Annual winter
precipitation, Annual spring temperature<br />
<strong>Predictor variables: random effects:</strong> Site, year</p>
<p>The simplest way to model random effects is to include them as
<strong>random intercepts</strong>– that is, the intercept term changes
randomly with each factor level.</p>
<p>In many cases, simply adding a random intercept term for each random
effect is appropriate for accounting for sources of non-independence in
your data set- but in many cases it is not sufficient. That is because
the slope (the relationship between your response and predictor– the
thing you are usually most interested in making inference about) can
itself vary depending on your random effect levels. This is called a
<strong>random slopes</strong> model. Here is an equation to represent
the simpler random-intercept analysis:</p>
<p><span class="math inline">\(Clutch \space size = \beta_0 + \beta_1
\cdot precip_t + \beta_2 \cdot temp_t + \gamma_{site} + \gamma_{year} +
\epsilon_{obs}\)</span></p>
<p>Here we now have three sources of ‘error’: a random (normally
distributed) term for each site (<span
class="math inline">\(\gamma_{site}\)</span>), a random (normally
distributed) term for each year, and a normally distributed residual
error term (<span class="math inline">\(\epsilon_{obs}\)</span>).</p>
<p>If we want to include random slope and random intercept terms (which
is often the most appropriate model), the equation gets a bit more
complicated:</p>
<p><span class="math inline">\(Clutch \space size = \beta_0 + \beta_1
\cdot precip_t + \beta_2 \cdot temp_t + \gamma_{site} + \gamma_{year} +
\gamma_{site, \beta_1}\cdot precip_t + \gamma_{site, \beta_2}\cdot
temp_t + \epsilon_{obs}\)</span></p>
<p>Here we have two additional “error” terms that allow the slope terms
(beta1 and beta2) to vary randomly with each site and year.</p>
</div>
<div id="nested-random-effects" class="section level3">
<h3>Nested random effects</h3>
<p>You will often read descriptions of mixed-effects models saying
things like “Individual and site were included as random effects, with
individual nested within Site”.</p>
<p>Let’s imagine we randomly selected 10 sites and within each site we
capture a random sample of tortoises and we measure tortoise clutch size
for 4 consecutive years for each tortoise.</p>
<p>In this case, we have two potential random effects: site (random
subset of a much larger set of potential sites) and individual (random
subset of a much larger set of individuals within each site). Individual
#1 from Site #1 is obviously a different individual than Individual #1
from Site #2. So we can’t simply include a simple random effect term for
“Individual #1”. Since there are many “Individual #1”s, each “Individual
#1” must get its own random effect! In this case, Individual is nested
within Site!</p>
<p>Let’s contrast this with a non-nested (crossed) random effect- let’s
say site and year.</p>
<p>In this case, Year “2014” in site #1 is the same as Year “2014” in
site #2. Therefore the random effect associated with year “2014” does
not differ depending on site. In this case, site and year are
independent, non-nested random effects!</p>
</div>
<div id="assumptions-of-mixed-effects-regression"
class="section level3">
<h3>Assumptions of mixed-effects regression</h3>
<p>The assumptions of mixed-effects regression are the same as in
classical linear regression (for mixed-effects regression models) or
generalized linear models (for generalized linear mixed models; GLMM).
The only additional assumption is this:</p>
<ul>
<li>All random effects are normally distributed!</li>
</ul>
<p>In some more complex models you might encounter models that assume
random effects take other distributions- but this is still VERY rare to
see!</p>
</div>
<div id="example-mixed-effects-regression-in-r" class="section level3">
<h3>Example: mixed-effects regression in R</h3>
<p>The ‘workhorse’ package in R for fitting generalized linear
mixed-effects regression models (GLMM) is the ‘lme4’ package. However,
there are some other packages you should be aware of that can make your
life easier. One such package is “glmmTMB”- I have found this package
has more flexibility and tends to have less trouble fitting complex
mixed-effects models.</p>
<p>We will use <a href="tundra2.csv">this dataset</a> as our example -
this is a data set on carbon balance in the tundra. This example is
taken from <a
href="https://bbolker.github.io/mixedmodels-misc/ecostats_chap.html">this
website</a>.</p>
<pre class="r"><code># TUNDRA EXAMPLE ---------------------------

## Read in the data

mc1 &lt;- read.csv(&quot;tundra2.csv&quot;,sep=&quot;,&quot;,na.strings=c(&quot;-&quot;,&quot;NA&quot;))

summary(mc1)</code></pre>
<pre><code>##        X              Year          Site               GS.NEE        
##  Min.   : 1.00   Min.   :1966   Length:82          Min.   :-153.000  
##  1st Qu.:21.25   1st Qu.:1993   Class :character   1st Qu.: -55.350  
##  Median :41.50   Median :1998   Mode  :character   Median : -20.867  
##  Mean   :41.50   Mean   :1998                      Mean   : -10.012  
##  3rd Qu.:61.75   3rd Qu.:2005                      3rd Qu.:   3.275  
##  Max.   :82.00   Max.   :2010                      Max.   : 390.000  
##        n             cYear         
##  Min.   :1.000   Min.   :-31.8698  
##  1st Qu.:1.000   1st Qu.: -4.8698  
##  Median :1.000   Median :  0.6302  
##  Mean   :1.829   Mean   : -0.1015  
##  3rd Qu.:2.750   3rd Qu.:  7.1302  
##  Max.   :6.000   Max.   : 12.1302</code></pre>
<pre class="r"><code>table(mc1$Year)  # some years have many observations</code></pre>
<pre><code>## 
##   1966   1970   1971   1972   1983   1984   1985   1987   1990   1991   1992 
##      1      1      1      1      1      1      1      1      4      5      2 
##   1993   1994   1995   1996   1997   1998   1999   2000   2001   2002 2002.5 
##      4      4      6      4      3      1      2      2      3      2      1 
##   2003 2003.5   2004 2004.5   2005   2006   2007   2008 2008.5   2009   2010 
##      2      1      3      1      4      5      4      4      1      3      3</code></pre>
<pre class="r"><code>table(mc1$Site)  # some sites have many observations</code></pre>
<pre><code>## 
##       Anajtyvuk River, AK               APL-133, AK               Atqasuk, AK 
##                         1                         3                         1 
##          Barrow Peninsula                Barrow, AK           Daring Lake, CA 
##                         1                        12                         7 
##             Halmer-Yu, RU          Happy Valley, AK                 Healy, AK 
##                         1                         5                         7 
##        Imnavait Creek, AK                Ivotuk, AK       Kytalyk Reserve, RU 
##                         4                         2                         1 
##           Lek Vorkuta, RU           Meade River, AK    Pituffik Peninsula, GL 
##                         2                         1                         2 
##           Prudhoe Bay, AK                Sagwon, AK       Samoylov Island, RU 
##                         7                         1                         1 
##                Talnik, RU Toolik &amp; Happy Valley, AK                Toolik, AK 
##                         1                         1                        12 
##                U-PAD, AK      West Dock &amp; U-PAD, AK            Zachenberg, GL 
##                         2                         1                         6</code></pre>
<pre class="r"><code>library(ggplot2)

## visualize net ecosystem exchange by year- varying by site

ggplot(mc1,aes(x=Year,y=GS.NEE,colour=Site)) +
    geom_point() +
    geom_smooth(method=&quot;lm&quot;,alpha=0.3) +
    scale_y_continuous(limits=c(-150,400),oob=scales::squish)</code></pre>
<p><img src="LECTURE9_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Okay now let’s fit a mixed-effects regression model with Net
Ecosystem Exchange (NEE) as the response variable and Year as the
fixed-effect (covariate). For our random effect we will have site- and
the intercept and trend (slope term) can vary with site. That is, we
have random intercept terms and random slope terms for each site.</p>
<p>Fitting a mixed model in ‘lme4’ (using the <code>lmer()</code>
function or <code>glmer()</code> function) looks a lot like fitting a
linear model in ‘lm’.</p>
<pre class="r"><code>library(lme4)
cmod_lmer &lt;- lmer(GS.NEE ~ cYear + (1+cYear|Site),
                data=mc1, weights=n)</code></pre>
<p>A couple notes: first of all, the ‘weights’ term is there because
some observations are aggregated- that is, there are multiple
observations for a given site/year combination- those observations that
aggregate 3 observations get triple the weight of a site/year
combination with only one observation.</p>
<p>Secondly, note that year is treated as a fixed effect in this model.
That is- we are looking for a trend in our response variable over
time!</p>
<p>Third, don’t be surprised if you get a ‘singular fit’ warning. This
is fairly common to see, and doesn’t necessarily mean you can’t use the
model. But it means that lme4 struggled to fit the model and often some
of the parameters may have very wide confidence bounds!</p>
<p>Let’s look at the model results using ‘summary’:</p>
<pre class="r"><code>summary(cmod_lmer)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: GS.NEE ~ cYear + (1 + cYear | Site)
##    Data: mc1
## Weights: n
## 
## REML criterion at convergence: 874.2
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.90221 -0.35038 -0.07972  0.30155  2.93141 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  Site     (Intercept)  116.05  10.773        
##           cYear         19.95   4.467   -1.00
##  Residual             3355.16  57.924        
## Number of obs: 82, groups:  Site, 24
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  -16.296      7.338  -2.221
## cYear         -3.745      1.341  -2.792
## 
## Correlation of Fixed Effects:
##       (Intr)
## cYear -0.417
## optimizer (nloptwrap) convergence code: 0 (OK)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<p>The results from the <code>summary()</code> function should look
somewhat familiar! But note that there are no p-values associated with
your fixed effects (regression coefficients)- just t-statistics! This is
because it is difficult to compute the degrees of freedom- statisticians
disagree about how and if p-values can/should be computed for these
models.</p>
<p>Also note that the summary now includes a summary of the random
effects. One red flag here is that the random intercept term and random
slope terms are perfectly (negatively) correlated (Corr=-1). This is the
reason for the ‘singular’ warning in this case.</p>
<p>From the random effects summary we can see that site explains a
relatively small percent of the total variance among observations.</p>
<p>To fit the model using glmmTMB we can use the following code:</p>
<pre class="r"><code>library(glmmTMB)
cmod_glmmTMB &lt;- glmmTMB(GS.NEE ~ cYear + (1+cYear|Site),
                data=mc1,
                weights=n,REML=F)

summary(cmod_glmmTMB)   # note NAs present</code></pre>
<pre><code>##  Family: gaussian  ( identity )
## Formula:          GS.NEE ~ cYear + (1 + cYear | Site)
## Data: mc1
## Weights: n
## 
##      AIC      BIC   logLik deviance df.resid 
##       NA       NA       NA       NA       76 
## 
## Random effects:
## 
## Conditional model:
##  Groups   Name        Variance  Std.Dev. Corr  
##  Site     (Intercept) 3.841e-02  0.196         
##           cYear       3.148e+01  5.611   -0.79 
##  Residual             1.543e+03 39.280         
## Number of obs: 82, groups:  Site, 24
## 
## Dispersion estimate for gaussian family (sigma^2): 1.54e+03 
## 
## Conditional model:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -22.347      5.579  -4.005 6.19e-05 ***
## cYear         -3.706      1.416  -2.617  0.00887 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># try a different optimizer -still doesn&#39;t work...
cmod_glmmTMB2 &lt;- update(cmod_glmmTMB,control=glmmTMBControl(optimizer=optim,
                                       optArgs=list(method=&quot;BFGS&quot;)))

summary(cmod_glmmTMB2)</code></pre>
<pre><code>##  Family: gaussian  ( identity )
## Formula:          GS.NEE ~ cYear + (1 + cYear | Site)
## Data: mc1
## Weights: n
## 
##      AIC      BIC   logLik deviance df.resid 
##       NA       NA       NA       NA       76 
## 
## Random effects:
## 
## Conditional model:
##  Groups   Name        Variance  Std.Dev.  Corr 
##  Site     (Intercept) 6.801e-48 2.608e-24      
##           cYear       3.162e+01 5.624e+00 1.00 
##  Residual             1.542e+03 3.927e+01      
## Number of obs: 82, groups:  Site, 24
## 
## Dispersion estimate for gaussian family (sigma^2): 1.54e+03 
## 
## Conditional model:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -22.411      5.127  -4.371 1.24e-05 ***
## cYear         -3.710      1.411  -2.629  0.00856 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># try a different specification- uncorrelated slope and intercept terms:

cmod_glmmTMB3 &lt;- glmmTMB(GS.NEE ~ cYear + (1|Site) + (0+cYear|Site),
                data=mc1,
                weights=n, REML=T)

summary(cmod_glmmTMB3)  # fits- not saying it&#39;s a good model!</code></pre>
<pre><code>##  Family: gaussian  ( identity )
## Formula:          GS.NEE ~ cYear + (1 | Site) + (0 + cYear | Site)
## Data: mc1
## Weights: n
## 
##      AIC      BIC   logLik deviance df.resid 
##   1564.5   1576.5   -777.2   1554.5       79 
## 
## Random effects:
## 
## Conditional model:
##  Groups   Name        Variance Std.Dev.
##  Site     (Intercept)  519.41  22.791  
##  Site.1   cYear         34.56   5.879  
##  Residual             1409.15  37.539  
## Number of obs: 82, groups:  Site, 24
## 
## Dispersion estimate for gaussian family (sigma^2): 1.41e+03 
## 
## Conditional model:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)  -21.490      8.465  -2.539  0.01112 * 
## cYear         -4.772      1.693  -2.818  0.00483 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The summary looks (vaguely) similar- but one difference you see is
that there are p-values on the regression coefficients now. This is due
to assumptions that are made in glmmTMB model fitting process (using the
Laplace approximation), which allows p-values to be computed!</p>
<p>Let’s perform some model diagnostics to test goodness-of-fit!</p>
<p>Since the standard linear regression assumptions apply, we could look
at our standard diagnostic plots:</p>
<pre class="r"><code>plot(cmod_lmer,type=c(&quot;p&quot;,&quot;smooth&quot;))</code></pre>
<p><img src="LECTURE9_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>plot(cmod_lmer,sqrt(abs(resid(.)))~fitted(.),
                  type=c(&quot;p&quot;,&quot;smooth&quot;),ylab=expression(sqrt(abs(resid))))</code></pre>
<p><img src="LECTURE9_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<pre class="r"><code>plot(cmod_lmer,resid(.,type=&quot;pearson&quot;)~cYear,
                  type=c(&quot;p&quot;,&quot;smooth&quot;))</code></pre>
<p><img src="LECTURE9_files/figure-html/unnamed-chunk-6-3.png" width="672" /></p>
<pre class="r"><code>qqnorm(residuals(cmod_lmer,type=&quot;pearson&quot;,scaled=T))</code></pre>
<p><img src="LECTURE9_files/figure-html/unnamed-chunk-6-4.png" width="672" /></p>
<p>The diagnostics look, well, okay! Let’s try “DHARMa”:</p>
<pre class="r"><code>library(DHARMa)
resids &lt;- simulateResiduals(cmod_lmer)  # similar results for the two different models
plot(resids)</code></pre>
<p><img src="LECTURE9_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>resids &lt;- simulateResiduals(cmod_glmmTMB3)
plot(resids)</code></pre>
<p><img src="LECTURE9_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
<pre class="r"><code>testResiduals(resids)</code></pre>
<p><img src="LECTURE9_files/figure-html/unnamed-chunk-7-3.png" width="672" /></p>
<pre><code>## $uniformity
## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  simulationOutput$scaledResiduals
## D = 0.18166, p-value = 0.008926
## alternative hypothesis: two-sided
## 
## 
## $dispersion
## 
##  DHARMa nonparametric dispersion test via sd of residuals fitted vs.
##  simulated
## 
## data:  simulationOutput
## dispersion = 1.221, p-value = 0.4
## alternative hypothesis: two.sided
## 
## 
## $outliers
## 
##  DHARMa outlier test based on exact binomial test with approximate
##  expectations
## 
## data:  simulationOutput
## outliers at both margin(s) = 3, observations = 82, p-value = 0.02812
## alternative hypothesis: true probability of success is not equal to 0.007968127
## 95 percent confidence interval:
##  0.007609277 0.103215022
## sample estimates:
## frequency of outliers (expected: 0.00796812749003984 ) 
##                                             0.03658537</code></pre>
<pre><code>## $uniformity
## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  simulationOutput$scaledResiduals
## D = 0.18166, p-value = 0.008926
## alternative hypothesis: two-sided
## 
## 
## $dispersion
## 
##  DHARMa nonparametric dispersion test via sd of residuals fitted vs.
##  simulated
## 
## data:  simulationOutput
## dispersion = 1.221, p-value = 0.4
## alternative hypothesis: two.sided
## 
## 
## $outliers
## 
##  DHARMa outlier test based on exact binomial test with approximate
##  expectations
## 
## data:  simulationOutput
## outliers at both margin(s) = 3, observations = 82, p-value = 0.02812
## alternative hypothesis: true probability of success is not equal to 0.007968127
## 95 percent confidence interval:
##  0.007609277 0.103215022
## sample estimates:
## frequency of outliers (expected: 0.00796812749003984 ) 
##                                             0.03658537</code></pre>
<p>Not perfect… and this is from a published study in Ecology Letters.
So you can probably forgive yourself if your GOF tests are not perfect
in your class projects!</p>
<p>Okay let’s visualize the random effects (both intercept and random
slope terms):</p>
<pre class="r"><code>library(lattice)
dotplot(ranef(cmod_lmer,condVar=TRUE),
          lattice.options=list(layout=c(1,2)))</code></pre>
<pre><code>## $Site</code></pre>
<p><img src="LECTURE9_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>If we want to test to see if year is explaining any of the variance,
we can run an F-test (ANOVA):</p>
<pre class="r"><code>library(car)
Anova(cmod_lmer)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: GS.NEE
##        Chisq Df Pr(&gt;Chisq)   
## cYear 7.7956  1   0.005237 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Or we can compare using AIC. When using AIC it’s generally
recommended not to use REML for model fitting.</p>
<pre class="r"><code>cmod_lmer2 &lt;- lmer(GS.NEE ~ cYear + (1+cYear|Site),
                data=mc1, weights=n,REML=F)
cmod_lmer3 &lt;- lmer(GS.NEE ~ 1 + (1+cYear|Site),
                data=mc1, weights=n,REML=F)

AIC(cmod_lmer2,cmod_lmer3)</code></pre>
<pre><code>##            df      AIC
## cmod_lmer2  6 894.1666
## cmod_lmer3  5 899.2038</code></pre>
<p>We can also use similar tests to see if a random effect is worth
including:</p>
<pre class="r"><code>cmod_lmer3 &lt;- lmer(GS.NEE ~ cYear + (1+cYear|Site),
                data=mc1, weights=n,REML=F)
cmod_lmer4 &lt;- lmer(GS.NEE ~ cYear + (1|Site),
                data=mc1, weights=n,REML=F)

anova(cmod_lmer4,cmod_lmer3)</code></pre>
<pre><code>## Data: mc1
## Models:
## cmod_lmer4: GS.NEE ~ cYear + (1 | Site)
## cmod_lmer3: GS.NEE ~ cYear + (1 + cYear | Site)
##            npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    
## cmod_lmer4    4 919.60 929.23 -455.80   911.60                         
## cmod_lmer3    6 894.17 908.61 -441.08   882.17 29.435  2  4.058e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>AIC(cmod_lmer3,cmod_lmer4)   # random slope term effect is not an artifact of random chance!</code></pre>
<pre><code>##            df      AIC
## cmod_lmer3  6 894.1666
## cmod_lmer4  4 919.6015</code></pre>
<p>We can also compute R-squared-like statistics to evaluate performance
for GLMMs:</p>
<pre class="r"><code># Compute r-squared for GLMM! -----------------

MuMIn::r.squaredGLMM(cmod_lmer)</code></pre>
<pre><code>##            R2m       R2c
## [1,] 0.1923366 0.4820433</code></pre>
<pre class="r"><code>MuMIn::r.squaredGLMM(cmod_glmmTMB)</code></pre>
<pre><code>##            R2m       R2c
## [1,] 0.2207863 0.7207649</code></pre>
<p>Note that if we had a categorical variable and wanted to run pairwise
comparisons, we could- using the <code>emmeans()</code> function (just
like with standard ANOVA).</p>
<p>If we want confidence intervals on our fixed effects, we can use the
‘confint’ function, just like in ordinary linear regression. Here we use
the Wald method (simplified version) and only extract confidence
intervals for the fixed effects.</p>
<pre class="r"><code>confint(cmod_lmer,parm=&quot;beta_&quot;,method=&quot;Wald&quot;)</code></pre>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -30.677776 -1.914152
## cYear        -6.374309 -1.116174</code></pre>
<p>Other things we might want to do with GLMM models (no examples
provided yet!): effects plots for main effect- and random
intercepts/slopes!</p>
</div>
<div id="nonconvergence" class="section level3">
<h3>Nonconvergence</h3>
<p>A common problem when fitting GLMMs is nonconvergence.</p>
<p>Some helpful tips can be found <a
href="https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html">here</a>.</p>
<p>Scaling and zero-centering all of your covariates can help!</p>
<p>Also, it can help to try using glmmTMB or other model fitting
packages in addition to ‘lme4’.</p>
<p><a href="LECTURE10.html">–go to next lecture–</a></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
