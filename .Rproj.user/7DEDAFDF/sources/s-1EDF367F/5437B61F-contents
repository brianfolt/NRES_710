---
title: "t-tests"
author: "NRES 710"
date: "Fall 2020"
output: 
  html_document: 
    theme: yeti
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

```

```{r echo=FALSE}

############################################################
####                                                    ####  
####  NRES 710, Lecture 2                               ####
####                                                    ####
####  Kevin Shoemaker and Ben Sullivan                  #### 
####  University of Nevada, Reno                        ####
####                                                    #### 
############################################################


############################################################
####  T-tests                                           ####
############################################################


```


## Download the R code for this lecture!

To follow along with the R-based lessons and demos, [right (or command) click on this link and save the script to your working directory](LECTURE2.R)


## Overview of statistical methods

Okay before we delve into t-tests, let's first give a broad overview of the analyses we will cover in this class (at least a tiny bit) and in which cases they are most appropriate:

### Continuous response variable

If your response variable is continuous (ratio, interval), common classical parametric statistical analyses include: t-tests, ANOVA, linear regression. Each of these tests is associated with non-parametric alternatives. In each case, we are interested in testing if the *population mean* of the continuous response variable is affected by the predictor variables (null hypothesis: nope, there is no effect!). Predictor variables, in turn, can be continuous or categorical (factor variables in R).   

#### Continuous response, categorical predictor

If your categorical predictor is binary (two levels), you can use a **two-sample t-test**. The non-parametric alternative is the **Mann-Whitney test**.

Example: Are females smaller than males? (null hypothesis: no difference)

If your categorical predictor has more than two levels, you can use an **ANalysis Of Variance (ANOVA)** followed by *pairwise comparisons* to test which categories differ from one another. You can visualize these relationships with (e.g.) a boxplot. The non-parametric alternative is the **Kruskal-Wallis test**.   

#### Continuous response, continuous predictor

If your predictor variable is continuous, you can use **linear regression**. If you just want to know if two variables are correlated but you are not interested in modeling one (the response) as a function of another (the predictor) you can run a **Pearson correlation test**. The non-parametric alternative is a **Spearman correlation test**.    

Example: What is the relationship between tree diameter and age- can tree diameter be used to effectively predict the age of a tree?  

#### Continuous response, both continuous and categorical predictors

In this case you can use **Analysis of Covariance (ANCOVA)** or just use **multiple linear regression**. In truth, linear regression and ANOVA are two sides of the same coin. You can run both analyses using the workhorse of linear modeling in R, the 'lm' function. Basically, if you have a continuous response variable, you can use the 'lm' function! The non-parametric alternative might be something like a **regression tree** analysis. 

### Discrete (count) response variable

With a discrete count response, you can use the same techniques as with a continuous response OR you can use **generalized linear models** with a Poisson error distribution (or other discrete probability distribution).

### Categorical response variable

If your response variable is categorical (factor variable, ordinal variable, binary variable) then your choice of statistical methods changes:

#### Categorical response variable, categorical predictor

If both your response variable and your predictor variable are categorical, then you can use a **chi-squared test** or a **Fisher exact test** to test for an association between the two variables. You may first summarize your data as a *contingency table* like we did with the 'lady tasting tea' example.

Example: test for an association between salamander color morph (melanistic vs wild-type) and mating behavior ('sneaker', territory holder).  
 
#### Categorical response variable, continuous predictor 

If your response variable is binary (true/false, two levels) and your response variable is continuous, you can use **logistic regression** (which is a type of *generalized linear model*). 

If your categorical response variable has more than two levels, you can use **multinomial logistic regression** (for categorical responses) or **ordinal logistic regression** (for ordinal responses). 
 
 
## Overview: t-tests

Okay, now let's move to the main topic of this lecture: t-tests! Here we have a continuous response variable and either no predictor variable (one sample t-test) or a binary predictor variable (two-sample t-test).

We have already performed simple versions of the t-test (one-sample t-tests). But t-tests are quite flexible and can be applied to a wide variety of null-hypothesis testing scenarios:

### One-sample t-test 

A one-sample t-test tests the consistency of the sample data with the null hypothesis that the sample was generated from a population with known mean (often zero, but not necessarily). As we have seen before, the t-statistic in this case is expressed as:

$t = \frac{(\bar{x}-\mu_0)}{s.e.}$

Where $\bar{x}$ is the sample mean, $s.e.$ is the standard error of the mean, and $\mu_0$ is the population mean under the null hypothesis.  

The t-statistic can be interpreted as the difference between the sample mean and the null population mean in units of standard errors. 

Under the null hypothesis, the sampling distribution of the t-statistic should follow a t distribution with n-1 degrees of freedom. 

```{r}

### one sample t-test (paired t-test is a type of one sample t-test)

sample.data <- rgamma(10,2,.1)
null.mean <- 10

sample.size <- length(sample.data)
sample.mean <- mean(sample.data)
sample.sd <- sd(sample.data)
std.err <- sample.sd/sqrt(sample.size)
t.stat <- (sample.mean-null.mean)/std.err

t.crit <- abs(qt(0.025,sample.size-1))   # for 2-tailed test

p.val <- (1-pt(abs(t.stat),sample.size-1))*2   # 


### alternatively use the t.test function:

t.test(sample.data,mu=null.mean)   # should get the same answer!


```


A common version of the one-sample t-test is the 'paired t-test', in which a measurement is taken on a single individual before and after a treatment is applied. An example of a paired t-test is the 'weight loss drug' example from the 'basic concepts' lecture. 



### Two-sample t-test 

A two-sample t-test tests the consistency of the sample data with the null hypothesis that sample A was generated from the same underlying population as sample B. The t-statistic in this case is expressed as:

$t = \frac{(\bar{x_A}-\bar{x_B})}{s.e._{pooled}}$

Where $\bar{x}$ is the sample mean, $s.e._{pooled}$ is the pooled standard error of the mean across both samples, and $\mu_0$ is the population mean under the null hypothesis.

The t-statistic in the 2-sample case can be interpreted as the difference between the sample mean from population A and the sample mean from population B, in units of (pooled) standard errors. 

The formula for the pooled standard error depends on whether your sample size is equal in the two samples and whether you are able to assume that the standard deviation is the same in the two underlying populations. 

For the 2-sample t-test, the degrees of freedom is equal to the total sample size across both samples minus 2.


```{r}

### two sample t-test 

sample.data.1 <- rnorm(15,55,10)
sample.data.2 <- rnorm(10,45,10)

sample.size.1 <- length(sample.data.1)
sample.size.2 <- length(sample.data.2)
sample.size.pooled <- length(sample.data.1) + length(sample.data.2)

sample.mean1 <- mean(sample.data.1)
sample.mean2 <- mean(sample.data.2)

sample.sd1 <- sd(sample.data.1)
sample.sd2 <- sd(sample.data.2)
sample.sd.pooled <- sqrt(((sample.size.1-1)*sample.sd1^2 + (sample.size.2-1)*sample.sd2^2)/(sample.size.pooled-2))

std.err.pooled <- sample.sd.pooled*sqrt(1/sample.size.1+1/sample.size.2)
t.stat <- (sample.mean1-sample.mean2)/std.err.pooled

t.crit <- abs(qt(0.025,sample.size-1))   # for 2-tailed test

p.val <- (1-pt(abs(t.stat),sample.size.pooled-2))*2   # 



### alternatively use the t.test function:

t.test(sample.data.1,sample.data.2,var.equal = T)   # should get the same answer!


```










And they can be one tailed vs two- tailed -  deals with directionality in the data.

In the simplest version of the t-test, there are equal sample size and equal variance. 

Here’s how we solve for a one-sample t-test. 


Degrees of freedom equal n-1. 
Here, we assume that 
	Samples are independent of each other
	Data are continuous
	The dependent variable should be approximately normally distributed*

Null hypothesis is that the difference between the population mean and the value for comparison is 0. 

But that’s not all! 

Two sample t-test: 

t=(x ̅_1-x ̅_2)/√((s_1^2)/n_1 +(s_2^2)/n_1 )
Degrees of Freedom  = (n1+ n2) – 2
Assumptions: 
	Data are continuous
	Samples are independent 
	Equal sample sizes
	Equal variance
	The data are approximately normally distributed* 

* T-tests have been shown to be robust against violations of these assumptions. Also, consider the CLT: the CLT doesn’t want the data themselves to be normally distributed, it wants the mean and variance to be representative of the population. The CLT provides the basis for this… but that’s not good enough for most people. 

Tails: if one tailed, 95 % of the distribution falls to the left or the right. 
If two tailed, 95 % of the distribution falls in the middle, with 2.5% of the distribution on each tail. 



Paired t-test: calculate differences. Then get the average, SD, SE. DF = differences – 1. Ho: µ=0

t=   (x_d ) ̅/〖SE〗_(x ̅d) 


Welch’s t-test: Unequal sample sizes, unequal variance. Like a two-sample t-test, but more flexible. Already robust against violations of normality. This is the DEFAULT version of a t-test in R. If you want an actual t-test, you need to tell it to do so! (var.equal = True, sample sizes must also be equal!)

t=  ((x_1 ) ̅-(x_2 ) ̅)/√((s_1^2)/n_1 -(s_2^2)/n_2 )

Degrees of freedom is more complicated, and is an approximation: 

DF=  〖((s_1^2)/n_1 +(s_2^2)/n_1 )〗^2/(〖((s_1^2)⁄n_1 )〗^2/(n_1-1)+〖((s_2^2)⁄n_2 )〗^2/(n_2-1))
It is usually a decimal number. 




```{r}

######
# T test examples


#### 
# T-tests
####

#Ttest
# Are my data greater than zero? 
Group0 <- c(0.5, -0.03, 4, 2.5, 0.89, 2.2, 1.7, 1.125)
hist(Group0)
t.test(Group0,alternative="greater") # This gets at directionality


#Are my data different than zero? 
Group0 <- c(0.5, -0.03, 4, 2.5, 0.89, 2.2, 1.7, 1.125)
hist(Group0)
t.test(Group0) # Okay, that's to zero. What about if it's different than 1? 

# are my data different than 1? 
t.test(Group0, mu=1)

# Now let's test two groups. 
# are the means equal? 
group1 <- c(7,9,6,6,6,11,6,3,8,7)
group2 <- c(11,13,8,6,14,11,13,13,10,11)
t.test(group1, group2, var.equal=T) # Notice how we set equal variance? Look at the output - "Two Sample t-test."
# is this one-tail or two? 

group1 <- c(7,9,6,6,6,11,6,3,8,7)
group2 <- c(11,13,8,6,14,11,13,13,10,11)
t.test(group1, group2) # T value does not change, but DF And p-value do! "Welch Two Sample t-test"
# WELCH IS THE DEFAULT IN R


```




## t-test sampling distribution



## Power analysis



[--go to next lecture--](LECTURE3.html) 

















