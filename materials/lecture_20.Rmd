---
title: "Tying It All Together"
author: "NRES 710"
date: "Last compiled: `r Sys.Date()`"
output: 
  html_document: 
    theme: yeti
    toc: yes
    toc_float: yes
    css: styles.css
---

<script type="text/x-mathjax-config">
MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
  MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
    cancel: ["Extension","cancel"],
    bcancel: ["Extension","cancel"],
    xcancel: ["Extension","cancel"],
    cancelto: ["Extension","cancel"]
  });
});
</script>

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	cache = TRUE
	)
```

```{r echo=FALSE}

#  NRES 710, Tying It All Together
#     University of Nevada, Reno
#     Review of Class and Next Steps

```

At this point, we have covered all the material in many introductory graduate student courses. So I want to take the final day to review what we have covered so far.

One of the ways we were able to cover so much ground in this class is we focused all of our efforts on the **general linear model**.

Up to this point, we have covered most things that you can do on the 'X-side' of the statistical model.

In future classes you might take, you might adjust things on the 'Y-side' of the equation -- using multivariate statistics, for example.

## Purpose of Statistics

In the very first class, I said the purpose of statistics was to estimate **truth** using **facts**. Data are our facts -- measurements of truth -- and we use statistics to analyze our data and estimate truth.

We generally want to know: what is the relationship between X and Y. Most questions we ask in our environmental science fields can be simplified into the idea of knowing the relationship between X and Y. More specifically... howe much does Y change with each change in X? Or what is the difference in Y among 2, 3, or 4 groups.

We read Johnson 1999 and learned that statistics really isn't about p-values! This is one piece of information, that is limited by important limitations.

**Q:** What two things influence p-values in any statistical test? **Sample size and effect size**

- Larger effects tend to have smaller p-values
- Small sample sizes have larger p-values; large sample sizes have small p-values.

For this reason, just because we get a significant result does not mean that our effects are biologically or environmentally significant. This means we need to look beyond the p-value and think about **biological significance**.

## Linear Regression with a Continuous X-variable

We learned about basic linear regression! And specifically we learned about the **general linear model**.

### General Linear Model

This model takes the form of:

$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ...+ \epsilon_1 \sim N(0, \sigma_1) + ... + \epsilon_{residual} \sim N(0, \sigma_{residual})$

We can have, in theory, as many X-variables as we want.

And we can also have multiple errors... each error has a mean of zero and a standard deviation of $\sigma$.

And we always have some residual error: error that is unexplained by all of the fixed and random effects.

If our X-variable is continuous, then the beta is a slope... that specifies how each unit change in X changes the response, Y.

If our X-variable is categorical, then the beta is the difference in Y between that group and the reference group.

**Q:** Which one is the reference group? **The one that is left out.**

We talked about the process by which we convert categories into math... using **dummy coding**... process of assigning 0s and 1s to groups. The reference is 0, the group is given 1.

We talked about the assumptions of regression and general linear models:

1. Continuous Y
2. Linear relation between X and Y (if X is continuous)
3. Homoscedasticity
4. Normally distributed residuals
5. No autocorrelation

We talked about how to test for the assumptions. I like using graphs; if we can see a violation, then it's something to worry about -- maybe. If you can't see it, it's not there.

### Predictions

We talked about prediction, and everything we said there is valid for the rest of the class. If I give you data, and you run an analysis that gives you betas and sigmas. Then I say: give me a predicted Y for some other X data. You can plug those new X-data into the model and make predictions for what the average Y would be. These predictions ignore the error terms, which is okay -- it predicts the average. If you wanted to make a prediction for one area in your random effect term (e.g., field 1), you could do that. But basically, predictions involve plugging in data and getting predicted outcomes for Y.

We always want to provide some measure of **uncertainty**. What's the difference between a prediction interval and a confidence interval?

- **Confidence intervals** deal with the uncertainty in the **mean**.
- **Prediction intervals** deal with individual possible outcomes, which have a wider range than confidence intervals.

With predictions, we might want to know what an outcome might be. And we want to incorporate that greater uncertainty.

### Categorical variables

We talked about categorical variables, t-tests, ANOVAs, etc. Analysis of categorical variables causes the betas to be *differences between the reference and the group of the beta.*

**Q:** When we run an ANOVA on categorical data with more than 2 groups, we get an overall p-value. What does that overall p-value tell us? **At least two groups are different from each other.**

**Q:** Why do we use an overall p-value? **To minimize Type I Error.**

Alternatively, if we want to compare many groups, we *could* run multiple t-tests. However, when we run many statistical tests, it increases our probability that we measure a significant effect that does not truly exist in nature. This is Type I error -- 'getting things wrong'. Running many statistical tests 'exposes us to risk of Type I error'.

If we are concerned about Type I Error, we could do a **post-hoc test**. Post-hoc tests are a form of test to compare differences between groups but that artificially inflates the p-values to maintain the experimentwise error rate at 0.05. Post-hoc tests don't change our measures of effects, but they increase uncertainty and p-values. This causes us to sometime fail to observe effects that are real in truth. There are many types of post-hoc tests, but **they all try to balance Type I Error and Power**.... but none of them do it perfectly.

### Categorical or Continuous X-variable

We discussed a special case where we might be able to treat our X-variable as either a categorical or continuous variable. Sometimes, we can't do this: if X is truly a category (e.g., habitat type), it can't be treated as continuous. And if you only have 1 value at each X, you can't treat it as categorical, because you have to have multiple samples at each X to treat something as categorical (replication!).

**Q:** If you have multiple samples at each X and they are numbers, how did I recommend you treat this as: continuous or categorical? **Continuous**.

**Q:** Why? **More simple (one beta), can make predictions (interpolate/extrapolate), and... more powerful (if relationship is linear)!** Continuous X requires fewer degrees of freedom, so greater sample size. If the assumption of linearity is NOT met, then treating it as categorical may have more power, because it makes no assumptions about linearity, and instead just compares differences between groups.

Generally, treat X as continuous, unless treating as categorical significantly improves fit of the data. We test for significant improvements of fit using an 'F-drop test' (a.k.a, partial likelihood ratio test).

**Q:** If we compare a linear model to a categorical model using an F-drop test and the result is significant, what does this tell us about the relationship between X and Y? **It's nonlinear!**

## Multivariable Models

Multi-variable modeling involves analyzing the response variable (Y) as a consequence of two or more X-variables at the same time! You don't always have to analyze multiple X-variables at the same time, but I suggested six reasons why this might be useful. What are those six reasons?

### Six reasons to use multivariable models

1. Elegance
2. Swamping
3. Collinearity
4. Interactions
5. Blocking variables
6. Pseudoreplication

**Elegance** means that the model is fancier but also more simple, because it allows the interpetation of multiple variables simultaneously.

**Swamping** is a problem where most of the variation in Y is explained by a single X variable. If you leave that X out, then you fail to observe an effect of other X-variables. By including multiple variables in a multivariable model, the model statistically controls for each variable when estimating effects of other variables.

We can only test for **interactions** if we run a multi-variable model.

We might want to include **blocking variables**. This is actually similar to accounting for swamping... again, controlling for random variation in our model to isolate effects of interest.

**Pseudoreplication**! We need to appropriately partition our samples and appropriately test for effects.

### Collinearity

**Q:** What's collinearity? **When you X-variables are correlated with eachother.** When your X-variables are correlated, there are two possible types of collinearity: **confounding** and **redundant**.

- **Confounding variables**: A variable is confounding if it <u>has it's own effect on Y</u> and it's also correlated with another X-variable.
- **Redundant variables**: A variable is confounding if it <u>has no effect on Y</u> and it's also correlated with another X-variable.

The larger the effect of the confounding variable, the greater it's potential to confound your results if you leave it out. 

**Q:** If we leave a confounding variable out of a model, what are the consequences? **Biased estimates**.

**Q:** If I were to ask you to produces unbiased estimates of two X-variables, what would you do? **Fit a multivariable model with both the x-variables!**

**Q:** If it's not a confounding variable, do you have to leave it in the model? **Nope.**

**Q:** But what is the consequence of leaving a redundant variable in the model? **Variance inflation.** You also get variance inflation when you leave confounding variables in the model, but you get unbiased estimates -- which is the most important part. 

A lot of folks remove collinear variables from models. This is okay if they are redundant variables -- but if they are confounding variables, then they are getting biased (bad, incorrect) estimates.

### Interactions

After collinearity, we moved on to a challenging topic... **interactions**!

**Q:** what is an interaction? **When the effect of one X-variable depends on the *value* of another X-variable.**

- The effect of a drug depends on sex
- The effect of age on size depends on sex
- The effect of competitors on weight gain depends the season
- Etc.

Interactions have non-parallel lines! Parallel lines have no interactions. If lines cross, you have an interaction. We can even see this on **bar charts**. If there is just a shift up or down; no interaction. If the bars shift in their order; interaction.

**Q:** How do we include an interaction in the general linear model? E.g., do we specify an interaction between X1 and X2? **We multiple them together and assign a beta for that**. We multiply these values times eachother. 

*Brian draw on board*: $\beta_3X_1X_2$

Adding interactions fundamentally *changes the meanings of the original betas*. The betas become restricted to being for only when the other X-variable is zero.

- Without the interaction, $\beta_1$ is the effect of $X_1$ on Y. 
- With the interaction, $\beta_1$ is the effect of $X_1$ on Y *only when X_2 is zero*.
- With the interaction, $\beta_3$ specifies how the effect of $X_1$ changes depending on the value of $X_2$. Or... how the effect of $X_2$ changes depending on the value of $X_1$.

**Q:** Once we show that $\beta_3$ is statistically non-zero (it's significant), what can we do to make our lives more simple...? **Break the dataset apart and run two more simple linear models: what is the effect of $X_1$ for each group in $X_2$**. 

- This won't exactly work as well if $X_1$ and $X_2$ are both continuous... we can create 3-dimensional graphs.

We can test for interactions by building them into our linear model and checking to see if the marginal p-values associated with interaction effects are significant or not.

However, if the interaction involves a categorical X-variable with more than 2 groups, we have to be careful here... The marginal p-values may not tell us whether there is a significant interaction or not. There are two things we can do: 
1. We can change the reference and re-run the model to make sure we test for all possible interactions, by testing for that third or more pairwise comparison.
2. We can fit a **complex model** with the interaction and a more simple model **without the interaction** and compare the two models using an F-drop test. This will test whether there is a significance of the interaction as a whole.

## Mixed Effect Models

### Random Effects

**Q:** What's the difference between a **random effect** and a **fixed effect**? **Fixed effects influence the *average* Y-value, whereas random effects influence the *variance* in Y.**

In order to include a random effect, that random 'block' has to have been <u>measured more than once</u>. 

**Q:** When do you want to use a random effect vs. a fixed effect?

- You are just trying to account for variation, you don't really care that the groups are different. You just want to account for those differences.
- There are a lot of groups! Hard to include fixed-effects for 30 groups, for example... a lot of betas.
- If your groups are just a random sample (random fields, forests, areas that you didn't choose specifically but where you got data from; areas that aren't focal effects in your analysis) -- these would be things you might want to include as a random effect.

**Q:** What's the disadvantage of leaving out a random effect in a randomized block design? **Less power**. You could leave this out, but you would lose power -- potentially due to swamping.

### Nested Designs

We next discussed nested designs. The problem with nested designs is that you have the potential for **pseudoreplication**! You have something that has been measured more than once (random effect) that is nested within one of your treatments/groups/variables.

Each random block is only associated with a certain value of X. E.g., a field that got all control, or a field got all treatment, or that individual is all drug, or that individual is all female. You have a nested design, which has potential for pseudoreplication.

Four types of **pseudoreplication**:

- Simple
- Sacrificial
- Temporal
- Implicit

## What Next?

There are many other statistics classes offered in the Natural Resources and Environmental Sciences (NRES) Department and other departments here at UNR. Here are a few that I am aware of:

**NRES 746: Advanced Analysis Methods in Natural Resources and Environmental Science**

- Learn non-linear approaches to building various statistical models.
- Learn basic programming operations to build statistical models 'from scratch', rather than using canned R-functions.
- Dive deeper into testing model assumptions, assessing 'goodness of fit', and model performance.
- Seems like a shotgun-style approach to teaching 'advanced methods' in statistical ecology.

So far in NRES 710, we have assumed that all the statistical data we work with has **normally-distributed error.** This is a foundational aspect of parameter or 'frequentist' statistics. In NRES 746, you will learn how to relax this assumption and instead build statistical models that use different, non-normal statistical distributions. These are often called 'generalized linear models' and can be used to estimate effects on probabilities or whole numbers, for example. 

**NRES 746: Advanced Analysis Methods in Natural Resources and Environmental Science**


[--the end--]()