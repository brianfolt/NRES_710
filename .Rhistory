B1 <- -1.8  # slope steepness - makes sense roadrunners would prefer flatter sites given their method of foraging
B2 <- 0     # soil depth - no relationship
B3 <- 0.26  # elevation first order
B4 <- -0.000021 #elevation second order
B5 <- -0.27 # tree density - negative relationship - "open country" was specified in the handout
B6 <- 0     # soil pH - no relationship
B7 <- 110   # CosAsp -note there is an INTERACTION TERM WITH CANOPY COVER
B8 <- 0.35  # PatchSize - positive relationship with tree patch size - larger tree patches mean larger openings?
B9 <- -3.5  # CanCov main effect - interaction term with slope aspect
B10 <- -3.1  # CanCov and CosAsp interaction term coefficient
# setting random number seed because I will build some random error into the calculated Roadrunner abundances
set.seed(-124)
# here is the calculation of roadrunner abundance!
AllData.df$RR <- B0 + B1*topo$Steep + B2*topo$SoilD + B3*topo$Elev + B4*I(topo$Elev^2) + B5*topo$TreeDens +
B6*topo$SoilpH + B7*topo$CosAsp + B8*topo$PatchSize + B9*topo$CanCov + B10*topo$CosAsp*topo$CanCov + 20*rnorm(1000)
head(AllData.df)
summary(AllData.df)
# explore this interaction effect between slope aspect and canopy cover
# remember that every interaction has "two sides" to it
coplot(RR ~ topo$CanCov | topo$CosAsp, panel=panel.smooth,columns=6)
coplot(RR ~ topo$CosAsp | topo$CanCov, panel=panel.smooth,columns = 6)
# explore this interaction effect between slope aspect and canopy cover
# remember that every interaction has "two sides" to it
coplot(RR ~ topo$CanCov | topo$CosAsp, panel=panel.smooth,columns=6)
coplot(RR ~ topo$CosAsp | topo$CanCov, panel=panel.smooth,columns = 6)
Full.fullsample.lm <- lm(RR ~ Steep + SoilD + Elev + I(Elev^2) + TreeDens + SoilpH + CosAsp * CanCov + PatchSize, data=AllData.df)
# randomly select 100 samples!
samp <- sample(nrow(AllData.df), 100)
RR.df <- AllData.df[samp,]
# Move RR to first column, convert to integer data type
# Rename dataframe PJ.RR
PJ.RR <- RR.df[,c(9,1,2,3,4,5,6,7,8)]
PJ.RR$RR <- as.integer(PJ.RR$RR)
head(PJ.RR)
PJ.RR <- read.csv("PJRoadRunner.csv")
head(PJ.RR)
panel.hist <- function(x, ...) {
usr <- par("usr")
on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks
nB <- length(breaks)
y <- h$counts
y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "white", ...)
}
pairs(PJ.RR, panel=panel.smooth, diag.panel=panel.hist)
round(cor(PJ.RR),3)
PJ.RR <- subset(PJ.RR,RR<10)
PJ.RR <- read.csv("PJRoadRunner.csv")
head(PJ.RR)
panel.hist <- function(x, ...) {
usr <- par("usr")
on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks
nB <- length(breaks)
y <- h$counts
y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "white", ...)
}
pairs(PJ.RR, panel=panel.smooth, diag.panel=panel.hist)
round(cor(PJ.RR),3)
PJ.RR <- subset(PJ.RR,RR>10)
full.lm <- (lm(RR ~ ., data=PJ.RR))
summary(full.lm)
plot(predict(full.lm)~PJ.RR$RR)
abline(0,1, col="blue")
plot(full.lm)
par(mfrow=c(2,2))
plot(full.lm)
par(mfrow=c(1,1))
vif(full.lm)
# Just for example:
try2.lm <- (lm(RR ~ . - Steep, data=PJ.RR))
vif(try2.lm)
try3.lm <- update(try2.lm, ~ . - CosAsp, data=PJ.RR)
vif(try3.lm)
try4.lm <- update(try3.lm, ~. - SoilD)
vif(try4.lm)
AIC(full.lm, try2.lm, try3.lm, try4.lm)
anova(full.lm, try2.lm, try3.lm, try4.lm)
coplot(PJ.RR$RR ~ PJ.RR$CanCov | PJ.RR$CosAsp, panel=panel.smooth,columns=6)
try5.lm <- update(try4.lm, ~. +CosAsp:CanCov)
# imagine you had realized the polynomial relationship with Elevation!
try6.lm <- update(try5.lm, ~. + I(Elev^2))
summary(try6.lm)
PJ.RR <- read.csv("PJRoadRunner.csv")
head(PJ.RR)
panel.hist <- function(x, ...) {
usr <- par("usr")
on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks
nB <- length(breaks)
y <- h$counts
y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "white", ...)
}
pairs(PJ.RR, panel=panel.smooth, diag.panel=panel.hist)
round(cor(PJ.RR),3)
PJ.RR <- subset(PJ.RR,RR>10)
pairs(PJ.RR, panel=panel.smooth, diag.panel=panel.hist)
round(cor(PJ.RR),3)
caret::findCorrelation(cor(PJ.RR))
PJ.RR <- subset(PJ.RR,RR>10)
predvars <- setdiff(names(PJ.RR),"RR")
predvars
round(cor(PJ.RR[,predvars]),3)
caret::findCorrelation(cor(PJ.RR))  # tells us to remove tree density!
PJ.RR <- subset(PJ.RR,RR>10)
full.lm <- (lm(RR ~ ., data=PJ.RR))
summary(full.lm)
plot(predict(full.lm)~PJ.RR$RR)
abline(0,1, col="blue")
par(mfrow=c(2,2))
plot(full.lm)
par(mfrow=c(1,1))
vif(full.lm)
# Just for example:
try2.lm <- (lm(RR ~ . - TreeDens, data=PJ.RR))
vif(try2.lm)
vif(try2.lm)
try3.lm <- update(try2.lm, ~ . + TreeDens - CosAsp, data=PJ.RR)
vif(try3.lm)
# Just for example:
try2.lm <- (lm(RR ~ . - TreeDens, data=PJ.RR))   # remove the variable that "caret" told us to remove
vif(try2.lm)    # steepness still has high VIF
try3.lm <- update(try2.lm, ~ . + TreeDens -Steep - CosAsp, data=PJ.RR)
vif(try3.lm)
# Just for example:
try2.lm <- (lm(RR ~ . - TreeDens, data=PJ.RR))   # remove the variable that "caret" told us to remove
vif(try2.lm)    # steepness still has high VIF
# Just for example:
try2.lm <- (lm(RR ~ . - TreeDens, data=PJ.RR))   # remove the variable that "caret" told us to remove
vif(try2.lm)    # steepness still has high VIF
try3.lm <- update(try2.lm, ~ . -Steep, data=PJ.RR)   # remove steepness
vif(try3.lm)
summary(try3.lm)
vif(full.lm)    # steepness has very high VIF- might be best to remove.
# Just for example:
try2.lm <- (lm(RR ~ . - Steep, data=PJ.RR))   # remove the highest VIF variable
vif(try2.lm)    # steepness still has high VIF
try3.lm <- update(try2.lm, ~ . +I(Elev^2), data=PJ.RR)   # add polynomial term for elevation
vif(try3.lm)  # no issues with VIF
vif(try2.lm)    # steepness still has high VIF
# Just for example:
try2.lm <- (lm(RR ~ . - Steep, data=PJ.RR))   # remove the highest VIF variable (steepness)
# Just for example:
try2.lm <- lm(RR ~ . - Steep, data=PJ.RR)   # remove the highest VIF variable (steepness)
vif(full.lm)    # steepness has very high VIF- might be best to remove.
# Just for example:
try2.lm <- lm(RR ~ . - Steep, data=PJ.RR)   # remove the highest VIF variable (steepness)
vif(try2.lm)    # might want to remove tree density- this is the variable identified by caret
try3.lm <- update(try2.lm, ~ . - TreeDens, data=PJ.RR)
try3.lm
vif(try3.lm)
summary(try3.lm)
try4.lm <- update(try3.lm, ~ . - SoilD)
vif(try4.lm)
summary(try4.lm)
try5.lm <- update(try4.lm, ~ . +I(Elev^2), data=PJ.RR)   # add polynomial term for elevation
summary(try5.lm)
AIC(full.lm, try2.lm, try3.lm, try4.lm, try5.lm)
anova(full.lm, try2.lm, try3.lm, try4.lm, try5.lm)
coplot(PJ.RR$RR ~ PJ.RR$CanCov | PJ.RR$CosAsp, panel=panel.smooth,columns=6)
try6.lm <- update(try5.lm, ~. +CosAsp:CanCov)
summary(try6.lm)
# remove the non-significant patch size
try7.lm <- update(try6.lm, ~. - PatchSize)
summary(try7.lm)
full.lm
true.lm <- lm(RR~Elev+I(Elev^2)+CosAsp*CanCov+Steep+TreeDens+PatchSize,data=PJ.RR)
AIC(full.lm, try2.lm, try3.lm, try4.lm, try5.lm, try6.lm, try7.lm, true.lm)
summary(try7.lm)
AIC(full.lm, try2.lm, try3.lm, try4.lm, try5.lm, try6.lm, try7.lm, true.lm)
par(mfrow=c(2,2))
plot(try8.lm)
plot(try7.lm)
par(mfrow=c(1,1))
plot(predict(try8.lm) ~ PJ.RR$RR)
abline(0,1, col="red", lwd=3)
par(mfrow=c(2,2))
plot(predict(try7.lm) ~ PJ.RR$RR)
abline(0,1, col="red", lwd=3)
library(effects)  #plot these effects!
# with partial residuals!
plot(allEffects(full.lm, partial.residuals=TRUE))
# after removing steepness and tree dens
plot(allEffects(try3.lm, partial.residuals=TRUE))
plot(Effect(c("CosAsp", "CanCov"), true.lm))
if(!require(MuMIn)){install.packages("MuMIn")}
library(MuMIn)
#  prevent fitting sub-models to different datasets
options(na.action = "na.fail")
head(PJ.RR)
full.dr <- dredge(full.lm, extra=c("R^2"))
subset(full.dr, delta<4)
# take out the interactions that weren't important. Add polynomial terms for Elevation, Slope steepness
full.intpoly.lm <- update(full.int.lm, ~ . + CosAsp:CanCov - CosAsp:Elev - TreeDens:CosAsp
- Elev + poly(Elev,2) - Steep + poly(Steep,2), data=PJ.RR)
#full.int.lm <- lm(RR ~ .^2, data=PJ.RR)
full.int.lm <- update(full.lm, ~ . + CosAsp:CanCov + CosAsp:Elev + TreeDens:CosAsp, data=PJ.RR)
full.int.dr <- dredge(full.int.lm, extra=c("R^2"))
subset(full.int.dr, delta<4)
# take out the interactions that weren't important. Add polynomial terms for Elevation, Slope steepness
full.intpoly.lm <- update(full.int.lm, ~ . + CosAsp:CanCov - CosAsp:Elev - TreeDens:CosAsp
- Elev + poly(Elev,2) - Steep + poly(Steep,2), data=PJ.RR)
full.intpoly.dr <- dredge(full.intpoly.lm)
subset(full.intpoly.dr, delta<4)
full.intpoly.dr
?cor()
rmd2rscript("materials/lecture_12.Rmd")
rmarkdown::render('materials/lecture_12.Rmd', 'word_document')
# Number of simulations
s <- 1000
# Empty vectors to save results from each simulation
simple_beta1 <- numeric(s)
simple_se1 <- numeric(s)
simple_p1 <- numeric(s)
simple_beta2 <- numeric(s)
multi_beta1 <- numeric(s)
multi_beta2 <- numeric(s)
multi_se1 <- numeric(s)
multi_p1 <- numeric(s)
r2 <- numeric(s)
vif <- numeric(s)
vif
# x2 = x1 + error(0, z), where
# z can range from 0.5 (highly correlated to x1) to 20 (not correlated at ~all)
z_values <- seq(0.5, 20, length.out = s)
z_values
r2[1] < 25
r2[1] <- 25
z_values
1:s
s = 1
# Number of datapoints per simulation
n <- 100
# x1
x1 <- runif(n, 0, 10) # Random, uniform variable; only simulated once
x1
# Number of datapoints per simulation
n <- 100
# x1
x1 <- runif(n, 0, 10) # Random, uniform variable; only simulated once
# error for y; only simulated once
error <- rnorm(n, 0, 2)
error
x1
x2 <- x1 + rnorm(n, 0, z_values[i])
plot(x1, x2)
z_values[i]
rnorm(n, 0, z_values[i])
x2 <- x1 + rnorm(n, 0, 1)
plot(x1, x2)
source("~/.active-rstudio-document", echo=TRUE)
x2 <- x1 + rnorm(n, 0, 0.1)
plot(x1, x2)
x2 <- x1 + rnorm(n, 0, z_values[i])
plot(x1, x2)
y <- 10 + 3 * x1 + 3 * x2 + error
plot(x1, y)
plot(x2, y)
# Number of datapoints per simulation
n <- 100
# x1
x1 <- runif(n, 0, 10) # Random, uniform variable; only simulated once
# error for y; only simulated once
error <- rnorm(n, 0, 2)
# X2 for each simulation
x2 <- x1 + rnorm(n, 0, z_values[i])
# Y for each
y <- 10 + 3 * x1 + 3 * x2 + error
plot(x1, y)
plot(x2, y)
x1
# Simple model
results1 <- lm(y ~ x1)
simple_beta1[i] <- summary(results1)$coefficients[2,1]
simple_se1[i] <- summary(results1)$coefficients[2,2]
simple_p1[i] <- summary(results1)$coefficients[2,4]
summary(results1)
z_values[i]
plot(x1 , x2)
results1 <- lm(y ~ x1)
summary(results1)
simple_beta1[i]
simple_se1[i]
simple_p1[i]
# Number of simulations
s <- 1000
# Empty vectors to save results from each simulation
simple_beta1 <- numeric(s)
simple_se1 <- numeric(s)
simple_p1 <- numeric(s)
multi_beta1 <- numeric(s)
multi_se1 <- numeric(s)
multi_p1 <- numeric(s)
r2 <- numeric(s)
vif <- numeric(s)
# x2 = x1 + error(0, z), where
# z can range from 0.5 (highly correlated to x1) to 20 (not correlated at ~all)
z_values <- seq(0.5, 20, length.out = s)
i=1
# Number of datapoints per simulation
n <- 100
# x1
x1 <- runif(n, 0, 10) # Random, uniform variable; only simulated once
# error for y; only simulated once
error <- rnorm(n, 0, 2)
# X2 for each simulation
x2 <- x1 + rnorm(n, 0, z_values[i])
# Y for each
y <- 10 + 3 * x1 + 3 * x2 + error
plot(y ~ x1)
results1 <- lm(y ~ x1)
summary(results1)
z
z[i]
z_values[i]
results2 <- lm(y ~ x1 + x2)
summary(results2)
plot(x1, x2)
lm(x2 ~ x1)
summary(lm(x2 ~ x1))
vif[i] <- car::vif(results2)["x1"]
vif[i]
rmd2rscript("materials/lecture_12.Rmd")
rmd2rscript <- function(infile="LECTURE2.Rmd"){
outfile <- gsub(".Rmd",".R",infile)
close(file(outfile, open="w"))   # clear output file
con1 <- file(infile, open="r")
con2 <- file(outfile, "w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("materials/lecture_12.Rmd")
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
# Set the seed for reproducibility
set.seed(123)
## Dataset 1
# Sample size
n <- 90
# Simulate X-variables
# Continuous variables: Latitude and Elevation
Latitude <- runif(n, 0, 1) * 5 + 37
Elevation <- runif(n, 0, 1) * 1000 + 2000
# Categorical variable: State
g <- 3 # number of groups
State <- factor(c(rep("Colorado", n/g), rep("Nevada", n/g), rep("Utah", n/g)))
# Dummy-code the States
dummy <- data.frame(model.matrix(~ State - 1))
colnames(dummy) <- c("Colorado", "Nevada", "Utah")
# Error
Error <- rnorm(n, mean = 0, sd = 1)
# Response variable: Size
Size <- 45 - 0.95*Latitude - 0.00167*Elevation + 2*dummy$Nevada + 1*dummy$Utah + Error
# Create dataframe
datum <- data.frame(Latitude=Latitude, State=State, Elevation=Elevation, Nevada=dummy$Nevada,
Utah=dummy$Utah, Size=Size)
# Save the CSV file
write.csv(datum, "exercise_4_dataset1.csv")
rmarkdown::render('materials/lecture_13.Rmd', 'word_document')
rmarkdown::render('materials/lecture_13.Rmd', 'word_document')
rmarkdown::render('materials/lecture_13.Rmd', 'word_document')
rmarkdown::render('materials/lecture_13.Rmd', 'word_document')
rmarkdown::render('materials/lecture_13.Rmd', 'word_document')
rmarkdown::render('materials/lecture_13.Rmd', 'word_document')
rmarkdown::render('materials/lecture_13.Rmd', 'word_document')
rmarkdown::render('materials/lecture_13.Rmd', 'word_document')
rmd2rscript("materials/lecture_13.Rmd")
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
# Set the seed for reproducibility
set.seed(123)
## Dataset 1
# Sample size
n <- 90
# Simulate X-variables
# Continuous variables: Latitude and Elevation
Latitude <- runif(n, 0, 1) * 5 + 37
Elevation <- runif(n, 0, 1) * 1000 + 2000
# Categorical variable: State
g <- 3 # number of groups
State <- factor(c(rep("Colorado", n/g), rep("Nevada", n/g), rep("Utah", n/g)))
# Dummy-code the States
dummy <- data.frame(model.matrix(~ State - 1))
colnames(dummy) <- c("Colorado", "Nevada", "Utah")
# Error
Error <- rnorm(n, mean = 0, sd = 1)
# Response variable: Size
Size <- 45 - 0.95*Latitude - 0.00167*Elevation + 2*dummy$Nevada + 1*dummy$Utah + Error
# Create dataframe
datum <- data.frame(Latitude=Latitude, State=State, Elevation=Elevation, Colorado=dummy$Colorado, Nevada=dummy$Nevada, Utah=dummy$Utah, Size=Size)
# Save the CSV file
write.csv(datum, "exercise_4_dataset1.csv")
# Set the seed for reproducibility
set.seed(123)
## Dataset 1
# Sample size
n <- 90
# Simulate X-variables
# Continuous variables: Latitude and Elevation
Latitude <- runif(n, 0, 1) * 5 + 37
Elevation <- runif(n, 0, 1) * 1000 + 2000
# Categorical variable: State
g <- 3 # number of groups
State <- factor(c(rep("Colorado", n/g), rep("Nevada", n/g), rep("Utah", n/g)))
# Dummy-code the States
dummy <- data.frame(model.matrix(~ State - 1))
colnames(dummy) <- c("Colorado", "Nevada", "Utah")
# Error
Error <- rnorm(n, mean = 0, sd = 1)
# Response variable: Size
Size <- 45 - 0.95*Latitude - 0.00167*Elevation + 2*dummy$Nevada + 1*dummy$Utah + Error
# Create dataframe
datum <- data.frame(Latitude=Latitude, State=State, Elevation=Elevation, Colorado=dummy$Colorado, Nevada=dummy$Nevada, Utah=dummy$Utah, Size=Size)
# Save the CSV file
write.csv(datum, "exercise_4_dataset1.csv", row.names = FALSE)
## Dataset 2
# Sample size
n <- 100
# Simulate two continuous X-variables
Cover <- runif(n, 0, 1)
Food <- 3 + 3*Cover + rnorm(n, 0, 0.5)
# Error
Error <- rnorm(n, mean = 0, sd = 0.1)
# Response variable: Density
MarmotDensity <- 0.01 + 3*Cover + 2*Food + Error
# Create dataframe
datum <- data.frame(Cover = Cover, Food = Food, MarmotDensity = MarmotDensity)
# Save the CSV file
write.csv(datum, "exercise_4_dataset2.csv", row.names = FALSE)
## Dataset 3
# Sample size
n <- 100
# X-variables
# The 'true' X-variable: RunOff
RunOff <- runif(n, 0, 100)
# Collinear X-variables
Sediment <- matrix(NA, n, 1)
for (i in 1:n){
# Each sediment value is simulated using the mean of the RunOff value with a bit of noise (3)
Sediment[i] <- rnorm(1, RunOff[i], 3)
}
Organic <- matrix(NA, n, 1)
for (i in 1:n){
# Each organic matter value is simulated using the mean of RunOff with a lot of noise (15)
Organic[i] <- rnorm(1, RunOff[i], 15)
}
# Error
Error <- rnorm(n, 0, 2)
# Response variable
Clarity <- 50 - 0.4 * RunOff + Error
# Dataframe
datum <- data.frame(Sediment, Organic, Clarity)
# Save the CSV file
write.csv(datum, "exercise_4_dataset3.csv", row.names = FALSE)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
### Dataset for class exercise: age + sex + age*sex
# This is similar to the Age, Sex, and Size data we simulated for in Lecture 12.
# There is no collinearity between Age and Sex, but now there is an interaction
# between Sex and Age.
# First dataset
# X variable
n <- 50
x1 <- c(rep("Female", n), rep("Male", n))
x2 <- runif(n * 2, 1, 10)
dummy <- data.frame(model.matrix(~ x1 - 1))
colnames(dummy) <- c("Female", "Male")
# Simulate error
Error <- rnorm(n * 2, 0, 0.8)
# Predict Y
Response <- 1 + 2 * x2 + 4 * dummy$Male + 1 * x2 * dummy$Male + Error
# Dataframe
datum <- data.frame(Age = x2, Sex = x1, Male = dummy$Male, Size = Response)
# Save as CSV
write.csv(datum, "lecture_13_dataset.csv")
