tukeytest <- TukeyHSD(plant.av)
tukeytest
layout(matrix(1,nrow=1,byrow = T))
plot(tukeytest)   #default plotting method for tukey test objects!
######
# alternative method
# run tukey test
emm <- emmeans(plant.lm,specs=c("group"))  # compute the treatment means with 'emmeans'
pairs(emm)    # run tukey test!
toplot <- as.data.frame(summary(emm))[,c("group","emmean","lower.CL","upper.CL")]
xvals <- barplot(toplot$emmean,names.arg = toplot$group,ylim=c(0,7))
arrows(xvals,toplot$lower.CL,xvals,toplot$upper.CL,angle=90,code=3)
text(xvals,c(6.4,6.4,6.4),labels = c("ab","a","b"),cex=1.5)
## two way interaction example
data("ToothGrowth")
summary(ToothGrowth)
table(ToothGrowth$supp,ToothGrowth$dose)   # three doses, two types of supplements
ToothGrowth$dose <- ordered(ToothGrowth$dose)  # convert dose variable to factor (make it categorical)
model <- lm(len~supp+dose,data=ToothGrowth)  # two way anova with no interaction
summary(model)
anova(model)
model_with_interaction <- lm(len~supp*dose,data=ToothGrowth)  # now try again with interactions
summary(model_with_interaction)
anova(model_with_interaction)
# visualize the interaction
# ?interaction.plot     # this base R function can be used to visualize interactions
with(ToothGrowth, {   # the "with" function allows you to only specify the name of the data frame once, and then refer to the columns of the data frame as if they were variables in your main environment
interaction.plot(dose, supp, len, fixed = TRUE, col = c("red","blue"), leg.bty = "o")
})
TukeyHSD(aov(model), "dose")   # run tukey test for the 'dose' variable in the ToothGrowth model
TukeyHSD(aov(model_with_interaction), "dose")   # run tukey test for the 'dose' variable in the ToothGrowth model
library(emmeans)
emm = emmeans(model_with_interaction,
specs= pairwise ~ dose:supp)
contrast(emm)
### Kruskal-Wallis example
## read in data:
Input =("
Group      Value
Group.1      1
Group.1      2
Group.1      3
Group.1      4
Group.1      5
Group.1      6
Group.1      7
Group.1      8
Group.1      9
Group.1     46
Group.1     47
Group.1     48
Group.1     49
Group.1     50
Group.1     51
Group.1     52
Group.1     53
Group.1    342
Group.2     10
Group.2     11
Group.2     12
Group.2     13
Group.2     14
Group.2     15
Group.2     16
Group.2     17
Group.2     18
Group.2     37
Group.2     58
Group.2     59
Group.2     60
Group.2     61
Group.2     62
Group.2     63
Group.2     64
Group.2    193
Group.3     19
Group.3     20
Group.3     21
Group.3     22
Group.3     23
Group.3     24
Group.3     25
Group.3     26
Group.3     27
Group.3     28
Group.3     65
Group.3     66
Group.3     67
Group.3     68
Group.3     69
Group.3     70
Group.3     71
Group.3     72
")
Data = read.table(textConnection(Input),header=TRUE)
Data$Group = factor(Data$Group,levels=unique(Data$Group))    # transform predictor variable to factor
#summarize values by group
groups <- unique(Data$Group)
ngroups <- length(groups)
sumry <- sapply(1:ngroups,function(i){temp <- subset(Data,Group==groups[i]); summary(temp$Value)}  )
colnames(sumry) <- groups
sumry
# histograms by group
library(ggplot2)
ggplot(Data, aes(x=Value)) +
geom_histogram(bins=10,aes(color=Group,fill=Group)) +
facet_grid(~Group)
# ## first install required packages if needed
#
# if(!require(dplyr)){install.packages("dplyr")}
# if(!require(FSA)){install.packages("FSA")}
# if(!require(DescTools)){install.packages("DescTools")}
# if(!require(multcompView)){install.packages("multcompView")}
model <- lm(Value~Group,data=Data)
summary(model)   # no treatment effects
anova(model)   # looks a little weird
layout(matrix(1:4,nrow=2,byrow=T))
plot(model)   # notice the outliers! And violation of normality
shapiro.test(residuals(model))
unlink('LECTURE5_cache', recursive = TRUE)
rmarkdown::render('LECTURE5.Rmd',rmarkdown::pdf_document())
rmarkdown::render('LECTURE7.Rmd',rmarkdown::pdf_document())
library(rmarkdown)
library(tidyverse)
install.packages("emmeans")
library(tidyverse)
install.packages("tidyverse")
?iris
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
data("titanic_train")
library(titanic)              # this 'loads' the package and needs to be done every time you run this script
data("titanic_train")
head(titanic_train)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
library(titanic)              # this 'loads' the package and needs to be done every time you run this script
data("titanic_train")
1/16
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
### confidence intervals ------------
# read in weightloss example...
# summary(weightloss.data)
#
# mean.weightloss    # mean weight loss
# std.error          # standard error of weight loss
curve(dt(x,sample.size),-4,4,xaxt="n",xlab="weight loss",ylab="probability density")
71.06*9
2826.00+1788.00-71.06*9
runif(1,30,70)
mean(runif(1,30,70))
mean(runif(1,30,70))
mean(runif(1,30,70))
mean(runif(1,30,70))
mean(runif(10,30,70))
mean(runif(10,30,70))
mean(runif(10,30,70))
mean(runif(10,30,70))
mean(runif(100,30,70))
mean(runif(100,30,70))
mean(runif(100,30,70))
mean(runif(1000,30,70))
mean(runif(10000,30,70))
mean(runif(1,30,70))
mean(runif(2,30,70))
mean(runif(3,30,70))
mean(runif(5,30,70))
mean(runif(10,30,70))
mean(runif(100,30,70))
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
##  NRES 710, Lecture 2
##    University of Nevada, Reno
##    Sampling distributions
# Yellow-legged frog example ---------------------
### ALL FROGS IN CA (the statistical population- all the frogs!)
allfrogs.bodysize <- rlnorm(10000,1.5,0.4)        # statistical 'population'
hist(allfrogs.bodysize,main="",xlab="SVL (mm)")   # plot out histogram
truemean_SVL <- mean(allfrogs.bodysize)           # the 'parameter'
truemean_SVL
mysample <- sample(allfrogs.bodysize,10)    # take sample of size 10 (10 frogs measured)
mean(mysample)   # compute the sample mean
mysample <- sample(allfrogs.bodysize,20)    # take sample of size 20 (20 frogs measured)
mean(mysample)   # compute the sample mean
lotsofsamples <- list()
for(s in 1:5000){
lotsofsamples[[paste0("sample",s)]] <- sample(allfrogs.bodysize,30)    # take sample of size 30 (20 frogs measured)
}
lotsofsamples$sample1
lotsofsamples$sample99
lotsofsamples$sample732
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
hist(rbinom(10000,1,.5),xlab="N heads out of 1")
hist(rbinom(10000,1,.5),xlab="N heads out of 1",freq = F)
hist(rbinom(10000,1,.5),xlab="N heads out of 1")
rbinom(10000,1,.5)
table(rbinom(10000,1,.5))
barplot(table(rbinom(10000,1,.5)),xlab="N heads out of 1")
barplot(table(rbinom(10000,1,.5)/10000),xlab="N heads out of 1")
barplot(table(rbinom(10000,1,.5))/10000,xlab="N heads out of 1")
barplot(table(rbinom(10000,1,.5))/10000,xlab="N heads out of 1",ylab="Probability")
par(mfrow=c(3,2))
for(i in seq(2,12,2)){
hist(rbinom(10000,i,.5),main=paste0("sample size = ",i),xlab=sprintf("N heads out of %s",i))
}
par(mfrow=c(3,2))
for(i in seq(2,12,2)){
barplot(table(rbinom(10000,1,.5))/10000,xlab=sprintf("N heads out of %s",i),ylab="Probability",main=paste0("sample size = ",i))
#hist(rbinom(10000,i,.5),main=paste0("sample size = ",i),xlab=sprintf("N heads out of %s",i))
}
par(mfrow=c(3,2))
for(i in seq(2,12,2)){
barplot(table(rbinom(10000,i,.5))/10000,xlab=sprintf("N heads out of %s",i),ylab="Probability",main=paste0("sample size = ",i))
#hist(rbinom(10000,i,.5),main=paste0("sample size = ",i),xlab=sprintf("N heads out of %s",i))
}
hist(rbinom(10000,1000,.5),xlab="N heads out of 1")
hist(rbinom(10000,1000,.5),xlab="N heads out of 1",freq = F)
barplot(table(rbinom(10000,1,.5))/10000,xlab="N heads out of 1",ylab="Probability")
par(mfrow=c(3,2))
for(i in seq(2,12,2)){
barplot(table(rbinom(10000,i,.5))/10000,xlab=sprintf("N heads out of %s",i),ylab="Probability",main=paste0("sample size = ",i))
#hist(rbinom(10000,i,.5),main=paste0("sample size = ",i),xlab=sprintf("N heads out of %s",i))
}
# Survey of common sampling distributions -----------------
# Sampling distribution: the sample mean
mysample <- c(4.1,3.5,3.7,6.6,8.0,5.4,7.3,4.4)
mysample
n <- length(mysample)    # sample size
sample.mean <- mean(mysample)  # sample mean
sample.stdev <- sd(mysample)   # sample standard deviation (r uses denominator of n-1 by default!)
std.error <- sample.stdev/sqrt(n)
std.error
sampdist <- function(x){dt((x-sample.mean)/std.error,n-1)}
curve(sampdist,0,11,ylab="probability density",xlab="value",main="sampling distribution for the sample mean!")
abline(v=sample.mean,col="green",lwd=3)
confint <- c(sample.mean+std.error*qt(0.025,n-1),sample.mean+std.error*qt(0.975,n-1))
abline(v=confint,col="blue",lty=2)
rmarkdown::render('index.Rmd', 'word_document')
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("INTRO.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
args(lm)
?sd
1/16
9/16
10/16
fact(8)
factorial(8)
factorial(8)/factorial(4)
factorial(8)/(factorial(4)*factorial(4))
17/70
prop.test
prop.test(c(4,5,6),c(10,10,10))
prop.test(c(4),c(10))
prop.test(c(50),c(100))
prop.test(10,26)
1788*2
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
barplot(table(rbinom(10000,1,.5))/10000,xlab="N heads out of 1",ylab="Probability")
par(mfrow=c(3,2))
for(i in seq(2,12,2)){
barplot(table(rbinom(10000,i,.5))/10000,xlab=sprintf("N heads out of %s",i),ylab="Probability",main=paste0("sample size = ",i))
#hist(rbinom(10000,i,.5),main=paste0("sample size = ",i),xlab=sprintf("N heads out of %s",i))
}
hist(rbinom(10000,1000,.5),xlab="N heads out of 1",freq = F)
hist(rbinom(10000,1000,.5),xlab="N heads out of 1000",freq = F)
hist(rbinom(10000,1000,.5),xlab="N heads out of 1000",freq = F, main="")
sqrt(1.36)
sd(c(4, 3, 5, 5, 2))
sqrt(1.7)
sampdist <- function(x){dt((x-sample.mean)/std.error,n-1)}
curve(sampdist,0,11,ylab="probability density",xlab="value",main="sampling distribution for the sample mean!")
abline(v=sample.mean,col="green",lwd=3)
confint <- c(sample.mean+std.error*qt(0.025,n-1),sample.mean+std.error*qt(0.975,n-1))
abline(v=confint,col="blue",lty=2)
## probability density function example
curve(dt(x,8),-4,4,xlab="possibilities",ylab='relative probability (prob density)')
## quantile function
# for continuous distribution
curve(qt(x,df=8),0,1,xlab="cumulative probability",ylab='quantile')
# for discrete distribution
curve(qpois(x,4),0,1,xlab="cumulative probability",ylab='quantile')
## cumulative distribution function
# for continuous distribution
curve(pt(x,df=8),-4,4,xlab="possibilities",ylab='cumulative probability')
# for discrete distribution
x <- barplot(sapply(0:10,function(t) ppois(t,2)),xlab="possibilities",ylab='cumulative probability')
axis(1,at=x,labels=0:10)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("INTRO.Rmd")
rmd2rscript("LECTURE1.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
df <- read.csv("GSW_height.csv")
GSWheight <- df$Height
GSWheight
mean.gsw <- mean(GSWheight)
sd.gsw <- sd(GSWheight)
sd.pop <- 4
mean.pop <- 79
n <- length(GSWheight)
s.e. <- sd.pop/sqrt(n)
null.height <- mean.pop   # null: GSW are sampled randomly from the pool of all NBA players. They are not fundamentally different!
z.statistic <- (mean.gsw-null.height)/s.e.
z.statistic
curve(dnorm(x),-3,3)    # we assume that the z statistic is normally distributed- standard normal!
abline(v=z.statistic,col="green",lwd=3)
p <- 1-pnorm(z.statistic)    # is the p value enough evidence to tell you that GSW players are taller than the NBA average??
p
pnorm(z.statistic)
pnorm(z.statistic)
# one vs two tailed demo
#my.data <- rnorm(15, 0.5, 1)   # generate sample data
my.data <- c(0.20119786,1.41700898,-0.72426698,0.44006284,0.01487128,-0.19031680,1.75470699,-0.81992816,2.31978530,  2.71442595,-0.31461411,0.52086138,-0.50580117,1.52260888,0.76454698)
samp.mean <- mean(my.data)
samp.sd <- sd(my.data)
samp.n <- length(my.data)
std.err <- samp.sd/sqrt(samp.n)
null.mean <- 0
t.statistic <- (samp.mean-null.mean)/std.err
### Two-tailed
curve(dt(x,samp.n-1),-3,3, main="Meaning of more extreme (two tailed version)",
ylab="probability density",xlab="t statistic")    # visualize the sampling distribution of the t-statistic
abline(v=t.statistic,lwd=2,col="blue")
xs <- seq(abs(t.statistic),10,0.05)
ys <- dt(xs,samp.n-1)
polygon(x=c(xs,rev(xs)),y=c(ys,rep(0,times=length(ys))),col="green",border=NA)
polygon(x=c(-xs,rev(-xs)),y=c(ys,rep(0,times=length(ys))),col="green",border=NA)
p.twosided <- pt(-abs(t.statistic),samp.n-1)*2     # two-tailed p-value
text(-2,0.3,paste("p =",round(p.twosided,4)))
### One-sided (alternative = 'greater')
curve(dt(x,samp.n-1),-3,3, main="Meaning of more extreme (one tailed version: greater than)",
ylab="probability density",xlab="t statistic")    # visualize the sampling distribution of the t-statistic
abline(v=t.statistic,lwd=2,col="blue")
xs <- seq(t.statistic,10,0.05)
ys <- dt(xs,samp.n-1)
polygon(x=c(xs,rev(xs)),y=c(ys,rep(0,times=length(ys))),col="green",border=NA)
p.onesided <- pt(-abs(t.statistic),samp.n-1)     # one-tailed p-value
text(-2,0.3,paste("p =",round(p.onesided,4)))
### t-crit in one tailed vs two tailed test
sample.size=7
curve(dt(x,sample.size-1),-8,4, main="2-tailed vs 1-tailed critical value",
xlab="t-statistic",ylab="probability density")
alpha <- 0.1
t.crit.twosided <- qt(alpha/2,sample.size-1)
abline(v=c(t.crit.twosided,abs(t.crit.twosided)),col="red",lwd=2)
t.crit.twosided <- qt(alpha/2,sample.size-1)
abline(v=c(t.crit.twosided,abs(t.crit.twosided)),col="red",lwd=2)
t.crit.onesided <- qt(alpha,sample.size-1)
abline(v=abs(t.crit.onesided),col="green",lwd=2)
abline(v=t.crit.onesided,col="blue",lwd=2)
legend("topleft",lwd=c(2,2,2),col=c("red","green","blue"),bty="n",legend=c("two-tailed crit value","one-tailed crit value (greater than)","one-tailed crit value (less than)"))
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("INTRO.Rmd")
rmd2rscript("LECTURE1.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
rmd2rscript("LECTURE5.Rmd")
rmd2rscript("LECTURE5.Rmd")
rmd2rscript("LECTURE6.Rmd")
rmd2rscript("LECTURE4.Rmd")
rmd2rscript("LECTURE5.Rmd")
rmd2rscript("LECTURE6.Rmd")
rmd2rscript("LECTURE7.Rmd")  ##
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
library(tidyverse)
tortdf <- tribble(
~ name, ~ pre_trans, post_trans,
Helen,	120,	426,
Thomas,	601,	511,
Hayleigh,	90,	155,
Maximilian,	451,	510,
Adele,	339,	325,
Conner,	183,	388
)
tortdf <- tribble(
~ name, ~ pre_trans, ~post_trans,
Helen,	120,	426,
Thomas,	601,	511,
Hayleigh,	90,	155,
Maximilian,	451,	510,
Adele,	339,	325,
Conner,	183,	388
)
tribble(
~ name, ~ pre_trans, ~post_trans,
Helen,	120,	426,
Thomas,	601,	511,
Hayleigh,	90,	155,
Maximilian,	451,	510,
Adele,	339,	325,
Conner,	183,	388
)
tortdf <- tribble(
~ name, ~ pre_trans, ~post_trans,
"Helen",	120,	426,
"Thomas",	601,	511,
"Hayleigh",	90,	155,
"Maximilian",	451,	510,
"Adele",	339,	325,
"Conner",	183,	388
)
tortdf
shootroot <- read_csv(ShootRoot.csv)
shootroot <- read_csv("ShootRoot.csv")
shootroot
?cor.test
library(glmmTMB)
citation("glmmTMB")
library(edfun)
citation("edfun")
?glm
