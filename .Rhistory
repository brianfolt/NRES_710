tortdf <- tribble(
~ name, ~ pre_trans, post_trans,
Helen,	120,	426,
Thomas,	601,	511,
Hayleigh,	90,	155,
Maximilian,	451,	510,
Adele,	339,	325,
Conner,	183,	388
)
tortdf <- tribble(
~ name, ~ pre_trans, ~post_trans,
Helen,	120,	426,
Thomas,	601,	511,
Hayleigh,	90,	155,
Maximilian,	451,	510,
Adele,	339,	325,
Conner,	183,	388
)
tribble(
~ name, ~ pre_trans, ~post_trans,
Helen,	120,	426,
Thomas,	601,	511,
Hayleigh,	90,	155,
Maximilian,	451,	510,
Adele,	339,	325,
Conner,	183,	388
)
tortdf <- tribble(
~ name, ~ pre_trans, ~post_trans,
"Helen",	120,	426,
"Thomas",	601,	511,
"Hayleigh",	90,	155,
"Maximilian",	451,	510,
"Adele",	339,	325,
"Conner",	183,	388
)
tortdf
shootroot <- read_csv(ShootRoot.csv)
shootroot <- read_csv("ShootRoot.csv")
shootroot
?cor.test
library(glmmTMB)
citation("glmmTMB")
library(edfun)
citation("edfun")
?glm
?airquality
pairs(airquality, panel = panel.smooth, main = "airquality data")
names(airquality)
library(tidyverse)
?select
airquality %>% select(!(name:Ozone))
airquality %>% select(!Ozone)
cor(airquality %>% select(!Ozone))
cor(airquality %>% select(!Ozone),use = "pairwise.complete.obs")
?confint
install.packages("effects")
library(effects)
names(airquality)
Ozone.full.lm <- lm(Ozone~Solar.R+Wind+Temp,data=airquality)
plot(allEffects(Ozone.full.lm, partial.residuals=FALSE))
plot(allEffects(Ozone.full.lm, partial.residuals=TRUE), partial.residual=list(cex=0.4, col="red"))
?allEffects
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
#  NRES 710, Lecture 6   -----------------------------
#   University of Nevada, Reno
#   Linear Regression
# Examples --------------------------------------
eggs.per.nest <- 100
n.nests <- 15
light <- rnorm(n.nests,50,10)   # make up some light pollution values (predictor var)
probsucc <- function(light){    # egg success as a function of light pollution
plogis(1.5-0.01*light)
}
hatchlings.successful <- rbinom(n.nests,eggs.per.nest,probsucc(light))   # determine number of successful eggs (response var)
#curve(probsucc,0,100)
plot(hatchlings.successful~light)  # plot the data
slope <- sum((light-mean(light))*(hatchlings.successful-mean(hatchlings.successful)))/sum((light-mean(light))^2)
intercept <- mean(hatchlings.successful) - slope*mean(light)
exp.successful <- intercept+slope*light # expected number of eggs for each observation
residuals <- hatchlings.successful-exp.successful
stderr <- sqrt(((1/(n.nests-2))*sum(residuals^2))/(sum((light-mean(light))^2)))    # standard error
t.stat <- (slope-0)/stderr    # t statistic
pval <- 2*pt(t.stat,n.nests-2)    # p value
# use lm() function instead (easy way!)
model <- lm(hatchlings.successful~light)
summary(model)   # get the same t stat and p-value hopefully!
# plot regression line!
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
# add confidence interval on the regression line
newdata <- data.frame(    # make a data frame containing the light values we want to make predictions for (spanning the range of light values in our data)
light = seq(20,80,1)
)
my.predict <- predict(model, newdata = newdata, interval = "confidence")  # 95% conf int by default
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
lines(newdata$light,my.predict[,"upr"],col="red",lty=2)   # add upper bound
lines(newdata$light,my.predict[,"lwr"],col="red",lty=2)   # add lower bound
my.intercept <- model$coefficients["(Intercept)"]
my.slope <- model$coefficients["light"]
expected.vals <- my.intercept+my.slope*light
my.residuals <- hatchlings.successful-expected.vals
my.residuals
### alternative way of getting residuals (best way!)
my.residuals2 <- model$residuals
### alternative way using predict function
my.residuals3 <- hatchlings.successful-predict(model)
### histogram of residuals
hist(my.residuals)
### test for normality
qqnorm(my.residuals)
shapiro.test(my.residuals)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
rstandard(model)
?rstandard
plot(my.residuals~light)
plot(model)
my.residuals <- model$residuals
my.standardized.residuals <- rstandard(model)
my.residuals <- model$residuals
my.standardized.residuals <- rstandard(model)
plot(my.residuals~light)
plot(my.standardized.residuals~light)
plot(my.residuals~predict(model))
plot(my.residuals~light)
plot(my.standardized.residuals~predict(model))
plot(my.residuals~predict(model))
my.residuals <- model$residuals
my.standardized.residuals <- rstandard(model)    # even better...
plot(my.residuals~predict(model))    # plot residuals against fitted values
# plot(my.standardized.residuals~predict(model))
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
########
# load the car package
library(car)
#######
# load the trees dataset
data(trees)
######
# visualize relationships among predictor vars
pairs(trees[,c("Girth","Height")])
######
# check for correlation in predictor variables
cor(trees[,c("Girth","Height")])   # predictor variables not highly correlated
# run a multiple regression model
my.mod <- lm(Volume~Girth+Height,data=trees)
# check variance inflation factors
car::vif(my.mod)
########
## mtcars multicollinearity example
mymod <- lm(mpg~disp+hp+wt,data=mtcars)
vif(mymod)
cor(mtcars.reduced)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
#  NRES 710, Lecture 6   -----------------------------
#   University of Nevada, Reno
#   Linear Regression
# Examples --------------------------------------
eggs.per.nest <- 100
n.nests <- 15
light <- rnorm(n.nests,50,10)   # make up some light pollution values (predictor var)
probsucc <- function(light){    # egg success as a function of light pollution
plogis(1.5-0.01*light)
}
hatchlings.successful <- rbinom(n.nests,eggs.per.nest,probsucc(light))   # determine number of successful eggs (response var)
#curve(probsucc,0,100)
plot(hatchlings.successful~light)  # plot the data
slope <- sum((light-mean(light))*(hatchlings.successful-mean(hatchlings.successful)))/sum((light-mean(light))^2)
intercept <- mean(hatchlings.successful) - slope*mean(light)
exp.successful <- intercept+slope*light # expected number of eggs for each observation
residuals <- hatchlings.successful-exp.successful
stderr <- sqrt(((1/(n.nests-2))*sum(residuals^2))/(sum((light-mean(light))^2)))    # standard error
t.stat <- (slope-0)/stderr    # t statistic
pval <- 2*pt(t.stat,n.nests-2)    # p value
# use lm() function instead (easy way!)
model <- lm(hatchlings.successful~light)
summary(model)   # get the same t stat and p-value hopefully!
# plot regression line!
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
# add confidence interval on the regression line
newdata <- data.frame(    # make a data frame containing the light values we want to make predictions for (spanning the range of light values in our data)
light = seq(20,80,1)
)
my.predict <- predict(model, newdata = newdata, interval = "confidence")  # 95% conf int by default
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
lines(newdata$light,my.predict[,"upr"],col="red",lty=2)   # add upper bound
lines(newdata$light,my.predict[,"lwr"],col="red",lty=2)   # add lower bound
my.intercept <- model$coefficients["(Intercept)"]
my.slope <- model$coefficients["light"]
expected.vals <- my.intercept+my.slope*light
my.residuals <- hatchlings.successful-expected.vals
my.residuals
### alternative way of getting residuals (best way!)
my.residuals2 <- model$residuals
### alternative way using predict function
my.residuals3 <- hatchlings.successful-predict(model)
### histogram of residuals
hist(my.residuals)
### test for normality
qqnorm(my.residuals)
shapiro.test(my.residuals)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
my.residuals <- model$residuals
my.standardized.residuals <- rstandard(model)    # even better...
plot(my.residuals~predict(model))    # plot residuals against fitted values
# plot(my.standardized.residuals~predict(model))
layout(matrix(1:4,2,byrow = T))
plot(model)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
## load the 'mtcars' data set
data(mtcars)
## define which variables to assess correlation for.
myvars <- c("disp","hp","wt")
## grab only the variables of interest
mtcars.reduced <- mtcars[,myvars]
## compute (pearson) correlations for all pairs of variables (correlation matrix)
cor.mat <- cor(mtcars.reduced)
cor.mat
## visualize correlations with the 'pairs' function
pairs(mtcars.reduced)
## run a correlation test- with 95% confidence interval
# default is Pearson product-moment correlation.
cor.test(mtcars$disp,mtcars$wt)
## now try a non-parametric version
cor.test(mtcars$disp,mtcars$wt, method = "kendall") # or spearman
########
# load the car package
library(car)
#######
# load the trees dataset
data(trees)
######
# visualize relationships among predictor vars
pairs(trees[,c("Girth","Height")])
######
# check for correlation in predictor variables
cor(trees[,c("Girth","Height")])   # predictor variables not highly correlated
# run a multiple regression model
my.mod <- lm(Volume~Girth+Height,data=trees)
# check variance inflation factors
car::vif(my.mod)
########
## mtcars multicollinearity example
mymod <- lm(mpg~disp+hp+wt,data=mtcars)
vif(mymod)
cor(mtcars.reduced)
?nls
plot(DNase$density~DNase$conc)
abline(model1)
data(DNase)
plot(DNase$density~DNase$conc)   # looks non-linear!
model1 <- lm(density~conc,data=DNase)
par(mfrow=c(2,2))
plot(model1)     # clear non-linearity (and non-normal residuals, and heteroskedasticity!)
par(mfrow=c(1,1))      # plot data with regression line - obvious issues!
plot(DNase$density~DNase$conc)
abline(model1)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("LECTURE6.Rmd")
TotVal_res_ms = Base_ms*2 +  (Tuition_res_9cred*4)*0.75 + Benefits*4
#################
Base_ms = 16000     # annual
Base_PhD = 20000   # annual
Tuition_res_9cred = 2826    # per semester
Benefits = 1788   # per semester
Tuition_nonres = 8271  # per semester (for nonresidents)
TotVal_res_ms = Base_ms*2 +  (Tuition_res_9cred*4)*0.75 + Benefits*4
TotVal_nonres_ms = Base_ms*2 +  (Tuition_res_9cred*4)*0.75 + Benefits*4 + Tuition_nonres*4
TotVal_res_phd = Base_PhD*2 +  (Tuition_res_9cred*4)*0.75 + Benefits*4
TotVal_nonres_phd = Base_PhD*2 +  (Tuition_res_9cred*4)*0.75 + Benefits*4 + Tuition_nonres*4
#################
?pairs
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(agricolae)
library(agricolae)
data("PlantGrowth")
plant.lm <- lm(weight ~ group, data = PlantGrowth)   #run the 'regression' model
plant.av <- aov(plant.lm)  # run anova test and print anova table
plant.av
plant.av
summary(plant.av)
tukeytest <- TukeyHSD(plant.av)
tukeytest
layout(matrix(1,nrow=1,byrow = T))
plot(tukeytest)   #default plotting method for tukey test objects!
# run tukey test
emm <- emmeans(plant.lm,specs=c("group"))  # compute the treatment means with 'emmeans'
library(emmeans)
pairs(emm)    # run tukey test!
# run tukey test
emm <- emmeans(plant.lm,specs=c("group"))  # compute the treatment means with 'emmeans'
pairs(emm)    # run tukey test!
toplot <- as.data.frame(summary(emm))[,c("group","emmean","lower.CL","upper.CL")]
xvals <- barplot(toplot$emmean,names.arg = toplot$group,ylim=c(0,7))
arrows(xvals,toplot$lower.CL,xvals,toplot$upper.CL,angle=90,code=3)
toplot <- as.data.frame(summary(emm))[,c("group","emmean","lower.CL","upper.CL")]
xvals <- barplot(toplot$emmean,names.arg = toplot$group,ylim=c(0,7))
arrows(xvals,toplot$lower.CL,xvals,toplot$upper.CL,angle=90,code=3)
text(xvals,c(6.4,6.4,6.4),labels = c("ab","a","b"),cex=1.5)
data("ToothGrowth")
summary(ToothGrowth)
table(ToothGrowth$supp,ToothGrowth$dose)   # three doses, two types of supplements
ToothGrowth$dose <- ordered(ToothGrowth$dose)  # convert dose variable to factor (make it categorical)
model <- lm(len~supp+dose,data=ToothGrowth)  # two way anova with no interaction
summary(model)
anova(model)
model_with_interaction <- lm(len~supp*dose,data=ToothGrowth)  # now try again with interactions
summary(model_with_interaction)
anova(model_with_interaction)
# visualize the interaction
# ?interaction.plot     # this base R function can be used to visualize interactions
with(ToothGrowth, {   # the "with" function allows you to only specify the name of the data frame once, and then refer to the columns of the data frame as if they were variables in your main environment
interaction.plot(dose, supp, len, fixed = TRUE, col = c("red","blue"), leg.bty = "o")
})
TukeyHSD(aov(model), "dose")   # run tukey test for the 'dose' variable in the ToothGrowth model
TukeyHSD(aov(model_with_interaction), "dose")   # run tukey test for the 'dose' variable in the ToothGrowth model
library(emmeans)
emm = emmeans(model_with_interaction,
specs= pairwise ~ dose:supp)
contrast(emm)
?update
?coplot
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("LECTURE4.Rmd")
rmd2rscript("LECTURE4.Rmd")
rmd2rscript("LECTURE5.Rmd")
rmd2rscript("LECTURE6.Rmd")
rmd2rscript("LECTURE6.Rmd")
rmd2rscript("LECTURE7.Rmd")  ##
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
#  NRES 710, Lecture 6   -----------------------------
#   University of Nevada, Reno
#   Linear Regression
# Examples --------------------------------------
eggs.per.nest <- 100
n.nests <- 15
light <- rnorm(n.nests,50,10)   # make up some light pollution values (predictor var)
probsucc <- function(light){    # egg success as a function of light pollution
plogis(1.5-0.01*light)
}
hatchlings.successful <- rbinom(n.nests,eggs.per.nest,probsucc(light))   # determine number of successful eggs (response var)
#curve(probsucc,0,100)
plot(hatchlings.successful~light)  # plot the data
slope <- sum((light-mean(light))*(hatchlings.successful-mean(hatchlings.successful)))/sum((light-mean(light))^2)
intercept <- mean(hatchlings.successful) - slope*mean(light)
exp.successful <- intercept+slope*light # expected number of eggs for each observation
residuals <- hatchlings.successful-exp.successful
stderr <- sqrt(((1/(n.nests-2))*sum(residuals^2))/(sum((light-mean(light))^2)))    # standard error
t.stat <- (slope-0)/stderr    # t statistic
pval <- 2*pt(t.stat,n.nests-2)    # p value
# use lm() function instead (easy way!)
model <- lm(hatchlings.successful~light)
summary(model)   # get the same t stat and p-value hopefully!
# plot regression line!
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
# add confidence interval on the regression line
newdata <- data.frame(    # make a data frame containing the light values we want to make predictions for (spanning the range of light values in our data)
light = seq(20,80,1)
)
my.predict <- predict(model, newdata = newdata, interval = "confidence")  # 95% conf int by default
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
lines(newdata$light,my.predict[,"upr"],col="red",lty=2)   # add upper bound
lines(newdata$light,my.predict[,"lwr"],col="red",lty=2)   # add lower bound
my.intercept <- model$coefficients["(Intercept)"]
my.slope <- model$coefficients["light"]
expected.vals <- my.intercept+my.slope*light
my.residuals <- hatchlings.successful-expected.vals
my.residuals
### alternative way of getting residuals (best way!)
my.residuals2 <- model$residuals
### alternative way using predict function
my.residuals3 <- hatchlings.successful-predict(model)
### histogram of residuals
hist(my.residuals)
### test for normality
qqnorm(my.residuals)
shapiro.test(my.residuals)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
my.residuals <- model$residuals
my.standardized.residuals <- rstandard(model)    # even better...
plot(my.residuals~predict(model))    # plot residuals against fitted values
# plot(my.standardized.residuals~predict(model))
layout(matrix(1:4,2,byrow = T))
plot(model)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
## load the 'mtcars' data set
data(mtcars)
## define which variables to assess correlation for.
myvars <- c("disp","hp","wt")
## grab only the variables of interest
mtcars.reduced <- mtcars[,myvars]
## compute (pearson) correlations for all pairs of variables (correlation matrix)
cor.mat <- cor(mtcars.reduced)
cor.mat
## visualize correlations with the 'pairs' function
pairs(mtcars.reduced)
## run a correlation test- with 95% confidence interval
# default is Pearson product-moment correlation.
cor.test(mtcars$disp,mtcars$wt)
## now try a non-parametric version
cor.test(mtcars$disp,mtcars$wt, method = "kendall") # or spearman (kendall generally preferred)
# variance inflation factors ---------------------
###
# load the car package
library(car)
###
# load the trees dataset
data(trees)
###
# visualize relationships among predictor vars
pairs(trees[,c("Girth","Height")])
###
# check for correlation in predictor variables
cor(trees[,c("Girth","Height")])   # predictor variables not highly correlated
# run a multiple regression model
my.mod <- lm(Volume~Girth+Height,data=trees)
# check variance inflation factors
car::vif(my.mod)
###
## mtcars multicollinearity example
mymod <- lm(mpg~disp+hp+wt,data=mtcars)
vif(mymod)
library(caret)
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
library(caret)
library(ggplot2)
library(tidyverse)
library(tidyverse)
