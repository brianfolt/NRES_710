if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("INTRO.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
args(lm)
?sd
1/16
9/16
10/16
fact(8)
factorial(8)
factorial(8)/factorial(4)
factorial(8)/(factorial(4)*factorial(4))
17/70
prop.test
prop.test(c(4,5,6),c(10,10,10))
prop.test(c(4),c(10))
prop.test(c(50),c(100))
prop.test(10,26)
1788*2
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
barplot(table(rbinom(10000,1,.5))/10000,xlab="N heads out of 1",ylab="Probability")
par(mfrow=c(3,2))
for(i in seq(2,12,2)){
barplot(table(rbinom(10000,i,.5))/10000,xlab=sprintf("N heads out of %s",i),ylab="Probability",main=paste0("sample size = ",i))
#hist(rbinom(10000,i,.5),main=paste0("sample size = ",i),xlab=sprintf("N heads out of %s",i))
}
hist(rbinom(10000,1000,.5),xlab="N heads out of 1",freq = F)
hist(rbinom(10000,1000,.5),xlab="N heads out of 1000",freq = F)
hist(rbinom(10000,1000,.5),xlab="N heads out of 1000",freq = F, main="")
sqrt(1.36)
sd(c(4, 3, 5, 5, 2))
sqrt(1.7)
sampdist <- function(x){dt((x-sample.mean)/std.error,n-1)}
curve(sampdist,0,11,ylab="probability density",xlab="value",main="sampling distribution for the sample mean!")
abline(v=sample.mean,col="green",lwd=3)
confint <- c(sample.mean+std.error*qt(0.025,n-1),sample.mean+std.error*qt(0.975,n-1))
abline(v=confint,col="blue",lty=2)
## probability density function example
curve(dt(x,8),-4,4,xlab="possibilities",ylab='relative probability (prob density)')
## quantile function
# for continuous distribution
curve(qt(x,df=8),0,1,xlab="cumulative probability",ylab='quantile')
# for discrete distribution
curve(qpois(x,4),0,1,xlab="cumulative probability",ylab='quantile')
## cumulative distribution function
# for continuous distribution
curve(pt(x,df=8),-4,4,xlab="possibilities",ylab='cumulative probability')
# for discrete distribution
x <- barplot(sapply(0:10,function(t) ppois(t,2)),xlab="possibilities",ylab='cumulative probability')
axis(1,at=x,labels=0:10)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("INTRO.Rmd")
rmd2rscript("LECTURE1.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
df <- read.csv("GSW_height.csv")
GSWheight <- df$Height
GSWheight
mean.gsw <- mean(GSWheight)
sd.gsw <- sd(GSWheight)
sd.pop <- 4
mean.pop <- 79
n <- length(GSWheight)
s.e. <- sd.pop/sqrt(n)
null.height <- mean.pop   # null: GSW are sampled randomly from the pool of all NBA players. They are not fundamentally different!
z.statistic <- (mean.gsw-null.height)/s.e.
z.statistic
curve(dnorm(x),-3,3)    # we assume that the z statistic is normally distributed- standard normal!
abline(v=z.statistic,col="green",lwd=3)
p <- 1-pnorm(z.statistic)    # is the p value enough evidence to tell you that GSW players are taller than the NBA average??
p
pnorm(z.statistic)
pnorm(z.statistic)
# one vs two tailed demo
#my.data <- rnorm(15, 0.5, 1)   # generate sample data
my.data <- c(0.20119786,1.41700898,-0.72426698,0.44006284,0.01487128,-0.19031680,1.75470699,-0.81992816,2.31978530,  2.71442595,-0.31461411,0.52086138,-0.50580117,1.52260888,0.76454698)
samp.mean <- mean(my.data)
samp.sd <- sd(my.data)
samp.n <- length(my.data)
std.err <- samp.sd/sqrt(samp.n)
null.mean <- 0
t.statistic <- (samp.mean-null.mean)/std.err
### Two-tailed
curve(dt(x,samp.n-1),-3,3, main="Meaning of more extreme (two tailed version)",
ylab="probability density",xlab="t statistic")    # visualize the sampling distribution of the t-statistic
abline(v=t.statistic,lwd=2,col="blue")
xs <- seq(abs(t.statistic),10,0.05)
ys <- dt(xs,samp.n-1)
polygon(x=c(xs,rev(xs)),y=c(ys,rep(0,times=length(ys))),col="green",border=NA)
polygon(x=c(-xs,rev(-xs)),y=c(ys,rep(0,times=length(ys))),col="green",border=NA)
p.twosided <- pt(-abs(t.statistic),samp.n-1)*2     # two-tailed p-value
text(-2,0.3,paste("p =",round(p.twosided,4)))
### One-sided (alternative = 'greater')
curve(dt(x,samp.n-1),-3,3, main="Meaning of more extreme (one tailed version: greater than)",
ylab="probability density",xlab="t statistic")    # visualize the sampling distribution of the t-statistic
abline(v=t.statistic,lwd=2,col="blue")
xs <- seq(t.statistic,10,0.05)
ys <- dt(xs,samp.n-1)
polygon(x=c(xs,rev(xs)),y=c(ys,rep(0,times=length(ys))),col="green",border=NA)
p.onesided <- pt(-abs(t.statistic),samp.n-1)     # one-tailed p-value
text(-2,0.3,paste("p =",round(p.onesided,4)))
### t-crit in one tailed vs two tailed test
sample.size=7
curve(dt(x,sample.size-1),-8,4, main="2-tailed vs 1-tailed critical value",
xlab="t-statistic",ylab="probability density")
alpha <- 0.1
t.crit.twosided <- qt(alpha/2,sample.size-1)
abline(v=c(t.crit.twosided,abs(t.crit.twosided)),col="red",lwd=2)
t.crit.twosided <- qt(alpha/2,sample.size-1)
abline(v=c(t.crit.twosided,abs(t.crit.twosided)),col="red",lwd=2)
t.crit.onesided <- qt(alpha,sample.size-1)
abline(v=abs(t.crit.onesided),col="green",lwd=2)
abline(v=t.crit.onesided,col="blue",lwd=2)
legend("topleft",lwd=c(2,2,2),col=c("red","green","blue"),bty="n",legend=c("two-tailed crit value","one-tailed crit value (greater than)","one-tailed crit value (less than)"))
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("INTRO.Rmd")
rmd2rscript("LECTURE1.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE2.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
rmd2rscript("LECTURE5.Rmd")
rmd2rscript("LECTURE5.Rmd")
rmd2rscript("LECTURE6.Rmd")
rmd2rscript("LECTURE4.Rmd")
rmd2rscript("LECTURE5.Rmd")
rmd2rscript("LECTURE6.Rmd")
rmd2rscript("LECTURE7.Rmd")  ##
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
library(tidyverse)
tortdf <- tribble(
~ name, ~ pre_trans, post_trans,
Helen,	120,	426,
Thomas,	601,	511,
Hayleigh,	90,	155,
Maximilian,	451,	510,
Adele,	339,	325,
Conner,	183,	388
)
tortdf <- tribble(
~ name, ~ pre_trans, ~post_trans,
Helen,	120,	426,
Thomas,	601,	511,
Hayleigh,	90,	155,
Maximilian,	451,	510,
Adele,	339,	325,
Conner,	183,	388
)
tribble(
~ name, ~ pre_trans, ~post_trans,
Helen,	120,	426,
Thomas,	601,	511,
Hayleigh,	90,	155,
Maximilian,	451,	510,
Adele,	339,	325,
Conner,	183,	388
)
tortdf <- tribble(
~ name, ~ pre_trans, ~post_trans,
"Helen",	120,	426,
"Thomas",	601,	511,
"Hayleigh",	90,	155,
"Maximilian",	451,	510,
"Adele",	339,	325,
"Conner",	183,	388
)
tortdf
shootroot <- read_csv(ShootRoot.csv)
shootroot <- read_csv("ShootRoot.csv")
shootroot
?cor.test
library(glmmTMB)
citation("glmmTMB")
library(edfun)
citation("edfun")
?glm
?airquality
pairs(airquality, panel = panel.smooth, main = "airquality data")
names(airquality)
library(tidyverse)
?select
airquality %>% select(!(name:Ozone))
airquality %>% select(!Ozone)
cor(airquality %>% select(!Ozone))
cor(airquality %>% select(!Ozone),use = "pairwise.complete.obs")
?confint
install.packages("effects")
library(effects)
names(airquality)
Ozone.full.lm <- lm(Ozone~Solar.R+Wind+Temp,data=airquality)
plot(allEffects(Ozone.full.lm, partial.residuals=FALSE))
plot(allEffects(Ozone.full.lm, partial.residuals=TRUE), partial.residual=list(cex=0.4, col="red"))
?allEffects
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
#  NRES 710, Lecture 6   -----------------------------
#   University of Nevada, Reno
#   Linear Regression
# Examples --------------------------------------
eggs.per.nest <- 100
n.nests <- 15
light <- rnorm(n.nests,50,10)   # make up some light pollution values (predictor var)
probsucc <- function(light){    # egg success as a function of light pollution
plogis(1.5-0.01*light)
}
hatchlings.successful <- rbinom(n.nests,eggs.per.nest,probsucc(light))   # determine number of successful eggs (response var)
#curve(probsucc,0,100)
plot(hatchlings.successful~light)  # plot the data
slope <- sum((light-mean(light))*(hatchlings.successful-mean(hatchlings.successful)))/sum((light-mean(light))^2)
intercept <- mean(hatchlings.successful) - slope*mean(light)
exp.successful <- intercept+slope*light # expected number of eggs for each observation
residuals <- hatchlings.successful-exp.successful
stderr <- sqrt(((1/(n.nests-2))*sum(residuals^2))/(sum((light-mean(light))^2)))    # standard error
t.stat <- (slope-0)/stderr    # t statistic
pval <- 2*pt(t.stat,n.nests-2)    # p value
# use lm() function instead (easy way!)
model <- lm(hatchlings.successful~light)
summary(model)   # get the same t stat and p-value hopefully!
# plot regression line!
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
# add confidence interval on the regression line
newdata <- data.frame(    # make a data frame containing the light values we want to make predictions for (spanning the range of light values in our data)
light = seq(20,80,1)
)
my.predict <- predict(model, newdata = newdata, interval = "confidence")  # 95% conf int by default
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
lines(newdata$light,my.predict[,"upr"],col="red",lty=2)   # add upper bound
lines(newdata$light,my.predict[,"lwr"],col="red",lty=2)   # add lower bound
my.intercept <- model$coefficients["(Intercept)"]
my.slope <- model$coefficients["light"]
expected.vals <- my.intercept+my.slope*light
my.residuals <- hatchlings.successful-expected.vals
my.residuals
### alternative way of getting residuals (best way!)
my.residuals2 <- model$residuals
### alternative way using predict function
my.residuals3 <- hatchlings.successful-predict(model)
### histogram of residuals
hist(my.residuals)
### test for normality
qqnorm(my.residuals)
shapiro.test(my.residuals)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
rstandard(model)
?rstandard
plot(my.residuals~light)
plot(model)
my.residuals <- model$residuals
my.standardized.residuals <- rstandard(model)
my.residuals <- model$residuals
my.standardized.residuals <- rstandard(model)
plot(my.residuals~light)
plot(my.standardized.residuals~light)
plot(my.residuals~predict(model))
plot(my.residuals~light)
plot(my.standardized.residuals~predict(model))
plot(my.residuals~predict(model))
my.residuals <- model$residuals
my.standardized.residuals <- rstandard(model)    # even better...
plot(my.residuals~predict(model))    # plot residuals against fitted values
# plot(my.standardized.residuals~predict(model))
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
########
# load the car package
library(car)
#######
# load the trees dataset
data(trees)
######
# visualize relationships among predictor vars
pairs(trees[,c("Girth","Height")])
######
# check for correlation in predictor variables
cor(trees[,c("Girth","Height")])   # predictor variables not highly correlated
# run a multiple regression model
my.mod <- lm(Volume~Girth+Height,data=trees)
# check variance inflation factors
car::vif(my.mod)
########
## mtcars multicollinearity example
mymod <- lm(mpg~disp+hp+wt,data=mtcars)
vif(mymod)
cor(mtcars.reduced)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
#  NRES 710, Lecture 6   -----------------------------
#   University of Nevada, Reno
#   Linear Regression
# Examples --------------------------------------
eggs.per.nest <- 100
n.nests <- 15
light <- rnorm(n.nests,50,10)   # make up some light pollution values (predictor var)
probsucc <- function(light){    # egg success as a function of light pollution
plogis(1.5-0.01*light)
}
hatchlings.successful <- rbinom(n.nests,eggs.per.nest,probsucc(light))   # determine number of successful eggs (response var)
#curve(probsucc,0,100)
plot(hatchlings.successful~light)  # plot the data
slope <- sum((light-mean(light))*(hatchlings.successful-mean(hatchlings.successful)))/sum((light-mean(light))^2)
intercept <- mean(hatchlings.successful) - slope*mean(light)
exp.successful <- intercept+slope*light # expected number of eggs for each observation
residuals <- hatchlings.successful-exp.successful
stderr <- sqrt(((1/(n.nests-2))*sum(residuals^2))/(sum((light-mean(light))^2)))    # standard error
t.stat <- (slope-0)/stderr    # t statistic
pval <- 2*pt(t.stat,n.nests-2)    # p value
# use lm() function instead (easy way!)
model <- lm(hatchlings.successful~light)
summary(model)   # get the same t stat and p-value hopefully!
# plot regression line!
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
# add confidence interval on the regression line
newdata <- data.frame(    # make a data frame containing the light values we want to make predictions for (spanning the range of light values in our data)
light = seq(20,80,1)
)
my.predict <- predict(model, newdata = newdata, interval = "confidence")  # 95% conf int by default
plot(hatchlings.successful~light)  # plot the data
abline(intercept,slope,col="blue")
lines(newdata$light,my.predict[,"upr"],col="red",lty=2)   # add upper bound
lines(newdata$light,my.predict[,"lwr"],col="red",lty=2)   # add lower bound
my.intercept <- model$coefficients["(Intercept)"]
my.slope <- model$coefficients["light"]
expected.vals <- my.intercept+my.slope*light
my.residuals <- hatchlings.successful-expected.vals
my.residuals
### alternative way of getting residuals (best way!)
my.residuals2 <- model$residuals
### alternative way using predict function
my.residuals3 <- hatchlings.successful-predict(model)
### histogram of residuals
hist(my.residuals)
### test for normality
qqnorm(my.residuals)
shapiro.test(my.residuals)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
my.residuals <- model$residuals
my.standardized.residuals <- rstandard(model)    # even better...
plot(my.residuals~predict(model))    # plot residuals against fitted values
# plot(my.standardized.residuals~predict(model))
layout(matrix(1:4,2,byrow = T))
plot(model)
layout(matrix(1:4,nrow=2,byrow = T))
plot(anscombe$y1~anscombe$x1,ylab="response",xlab="predictor")
plot(anscombe$y2~anscombe$x2,ylab="response",xlab="predictor")
plot(anscombe$y3~anscombe$x3,ylab="response",xlab="predictor")
plot(anscombe$y4~anscombe$x4,ylab="response",xlab="predictor")
## load the 'mtcars' data set
data(mtcars)
## define which variables to assess correlation for.
myvars <- c("disp","hp","wt")
## grab only the variables of interest
mtcars.reduced <- mtcars[,myvars]
## compute (pearson) correlations for all pairs of variables (correlation matrix)
cor.mat <- cor(mtcars.reduced)
cor.mat
## visualize correlations with the 'pairs' function
pairs(mtcars.reduced)
## run a correlation test- with 95% confidence interval
# default is Pearson product-moment correlation.
cor.test(mtcars$disp,mtcars$wt)
## now try a non-parametric version
cor.test(mtcars$disp,mtcars$wt, method = "kendall") # or spearman
########
# load the car package
library(car)
#######
# load the trees dataset
data(trees)
######
# visualize relationships among predictor vars
pairs(trees[,c("Girth","Height")])
######
# check for correlation in predictor variables
cor(trees[,c("Girth","Height")])   # predictor variables not highly correlated
# run a multiple regression model
my.mod <- lm(Volume~Girth+Height,data=trees)
# check variance inflation factors
car::vif(my.mod)
########
## mtcars multicollinearity example
mymod <- lm(mpg~disp+hp+wt,data=mtcars)
vif(mymod)
cor(mtcars.reduced)
?nls
plot(DNase$density~DNase$conc)
abline(model1)
data(DNase)
plot(DNase$density~DNase$conc)   # looks non-linear!
model1 <- lm(density~conc,data=DNase)
par(mfrow=c(2,2))
plot(model1)     # clear non-linearity (and non-normal residuals, and heteroskedasticity!)
par(mfrow=c(1,1))      # plot data with regression line - obvious issues!
plot(DNase$density~DNase$conc)
abline(model1)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("LECTURE6.Rmd")
