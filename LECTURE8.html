<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="NRES 710" />


<title>Generalized Linear Models (GLM)</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 710</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="schedule.html">Schedule</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="INTRO.html">Introduction to NRES 710</a>
    </li>
    <li>
      <a href="LECTURE1.html">Basic Concepts</a>
    </li>
    <li>
      <a href="LECTURE2.html">Sampling uncertainty</a>
    </li>
    <li>
      <a href="LECTURE3.html">Taxonomy of common statistics</a>
    </li>
    <li>
      <a href="LECTURE4.html">t-test and z-test</a>
    </li>
    <li>
      <a href="LECTURE5.html">chi-squared tests</a>
    </li>
    <li>
      <a href="LECTURE6.html">Linear Regression</a>
    </li>
    <li>
      <a href="LECTURE7.html">ANOVA</a>
    </li>
    <li>
      <a href="LECTURE8.html">GLM</a>
    </li>
    <li>
      <a href="LECTURE9.html">GLMM</a>
    </li>
    <li>
      <a href="LECTURE10.html">Next steps</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="EXERCISE1.html">Exercise- data summary functions</a>
    </li>
    <li>
      <a href="EXERCISE2.html">Exercise- t-tests</a>
    </li>
    <li>
      <a href="EXERCISE3.html">Exercise- simple linear regression</a>
    </li>
    <li>
      <a href="EXERCISE4.html">Exercise- multiple linear regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    More Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Links.html">Links</a>
    </li>
    <li>
      <a href="FINALPROJ.html">Final Projects</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Datasets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Data1.dat">Data1</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Generalized Linear Models (GLM)</h1>
<h4 class="author">NRES 710</h4>
<h4 class="date">Fall 2022</h4>

</div>


<div id="download-the-r-code-for-this-lecture" class="section level2">
<h2>Download the R code for this lecture!</h2>
<p>To follow along with the R-based lessons and demos, <a
href="LECTURE8.R">right (or command) click on this link and save the
script to your working directory</a></p>
</div>
<div id="overview-generalized-linear-models" class="section level2">
<h2>Overview: Generalized Linear Models</h2>
<p>Generalized Linear Models (GLM) are not generally covered in ‘intro’
stats classes, but they are so flexible and so common in ecology and
environmental science that you really need to know how to work with
these models!</p>
<p>The real data sets that we deal with as ecologists and environmental
scientists tend to violate some key assumptions of classical linear
regression or ANOVA. In particular, residuals are often non-normal and
variance is not equal (heteroskedastic) across the range of
predictions.</p>
<p>GLMs allow us to model response variables that are not amenable to
classical linear regression – but uses a model structure that closely
resembles linear regression. Pretty much everything about running a GLM
feels like linear regression. The primary function for running GLM
models (<code>glm()</code>) even looks very similar to the regression
function <code>lm()</code>.</p>
<p>GLMs are <em>parametric</em> analyses – it’s just that (1) we don’t
need to assume our response variable is normally distributed and (2) we
don’t need to assume the relationship between the response variable and
the predictor variable(s) is linear on the scale of the untransformed
response variable. Let’s look into each of these in more detail:</p>
<div id="alternative-error-distributions" class="section level3">
<h3>Alternative error distributions</h3>
<p>So we don’t need to assume the response variable is normally
distributed – but we do need to assume it is distributed according to
some known probability distribution – and we need to specify what
distribution we ARE assuming. We can assume that the response process is
Poisson distributed, or gamma distributed, or any of a host of other
distributions (GLMs are typically limited to the set of distributions
known as the “exponential family”). But we, the modelers, have to
specify which distribution to use!</p>
</div>
<div id="link-functions" class="section level3">
<h3>Link functions</h3>
<p>So we don’t need to assume the relationship between the mean of the
response variable and the predictor variable(s) is linear on the scale
of the untransformed response variable – but we DO assume that the
hypothesized relationship is linear on some transformation of the
response variable – and we need to specify what transformed version of
the response process we wish to assume linearity for. This is called the
‘link function’.</p>
<p>In the general case, a GLM can be described by the following
pseudo-equation:</p>
<p><span class="math inline">\(f(\mu)=\beta_0+\beta_1\cdot x_1+\beta_2
\cdot x_2 \ldots\)</span></p>
<p>The left side of this equation is the mean of the response variable,
transformed according to the specified link function. The right side of
this equation is called the <strong>linear predictor</strong> and
describes how the (transformed) mean response varies as a function of
the predictor variable(s).</p>
<p>To complete the picture, we represent the error distribution
(inherent variability among observations) according to whatever error
process we specified: e.g., a binomial distribution, Poisson
distribution, or a number of other possibilities.</p>
</div>
<div id="logistic-regression" class="section level3">
<h3>Logistic regression</h3>
<p>For example, we might have a <em>binary</em> response variable and a
<em>continuous</em> predictor variable. Making the assumption of
linearity would not necessarily make sense in this case.</p>
<p>Let’s first make up an example:</p>
<pre class="r"><code># logistic regression ----------------------

## made up data for glm #1 (logistic regression)

predictor &lt;- runif(100,0,50)
response &lt;- rbinom(100,1, plogis(-5 + 0.26*predictor) )

plot(response~predictor,ylim=c(-2,2))
abline(lm(response~predictor),col=&quot;red&quot;)   # overlay regression line</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>layout(matrix(1:4,nrow=2,byrow=2))
plot(lm(response~predictor))</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<p>Note that the predicted mean response at high values of the predictor
exceed 1- which is impossible for a binary response. In fact, the mean
(expected) value for a binary response is the same thing as the
“probability of success (frequency of obtaining a value of 1)” – and
probabilities are constrained between 0 and 1. Clearly we can’t make the
assumption of linearity on the un-transformed binary response.
Furthermore, the other diagnostic plots also do not look so hot…</p>
<p>One transformation that makes sense for a regression with a binary
response variable is the <strong>logit transformation</strong>. The
logit transformation is commonly used to take probabilities (which are
constrained between 0 and 1) and transform them to
<em>unconstrained</em> values that can vary between -Inf and Inf.</p>
<p>This way, the linear predictor (which is inherently unconstrained and
can therefore theoretically vary between -Inf and Inf) can always be
interpretable as a probability!</p>
<p>For example, take the following probabilities:</p>
<pre class="r"><code>probs &lt;- runif(10)
probs</code></pre>
<pre><code>##  [1] 0.41259901 0.69469295 0.05109803 0.46716814 0.94749137 0.61687316
##  [7] 0.87175578 0.44395651 0.83994030 0.23815826</code></pre>
<p>Here’s what happens if we apply the logit transformation:</p>
<p><span class="math inline">\(logit(p) =
log(\frac{p}{(1-p)})\)</span></p>
<pre class="r"><code>data.frame(
  p = probs,
  logit.p=log(probs/(1-probs))
)</code></pre>
<pre><code>##             p    logit.p
## 1  0.41259901 -0.3532315
## 2  0.69469295  0.8221520
## 3  0.05109803 -2.9215597
## 4  0.46716814 -0.1315167
## 5  0.94749137  2.8928403
## 6  0.61687316  0.4762973
## 7  0.87175578  1.9165729
## 8  0.44395651 -0.2251199
## 9  0.83994030  1.6577839
## 10 0.23815826 -1.1628034</code></pre>
<p>If our response variable is binary and we want to assume that the
mean response (on some transformed scale) is linearly dependent on our
predictor variable, the logit transformation is a good candidate for our
link function, because this way the mean response will never go below
zero or above one.</p>
<p>So instead of:</p>
<p><span class="math inline">\(\bar{y} = \beta_0 + \beta_1\cdot
x\)</span></p>
<p>We can use the <strong>logit link function</strong> and assume
instead that:</p>
<p><span class="math inline">\(logit(\bar{y}) = \beta_0 + \beta_1\cdot
x\)</span></p>
<p>If we solve for y, this equation becomes:</p>
<p><span class="math inline">\(\bar{y} = \frac{e^{\beta_0 + \beta_1\cdot
x}}{1+e^{\beta_0 + \beta_1\cdot x}}\)</span></p>
<p>This is what we do when we conduct a <em>logistic regression</em>!
Specifically, in a logistic regression we generally assume the
following:</p>
<p><strong>Response distribution</strong>: response variable is
binomially distributed. Often (but not necessarily), this takes the form
of a specific binomial distribution with size=1 (can only be zero or
one; also known as a Bernoulli distribution).</p>
<p><strong>Link function</strong>: the mean response (binomial
probability) is a linear function of the predictor variable(s) on the
logit scale.</p>
<p>We use a binomial response distribution because our response variable
is analogous to a coin flip. If you flip one coin you can get only a
zero or a one, just like the response variable. The binomial
distribution matches the response variable, so it is an appropriate
distribution to assume!</p>
<pre class="r"><code>  ## conduct logistic regression:

mydat &lt;- data.frame(response=response,predictor=predictor)
model &lt;- glm(response~predictor,family=binomial(link=&quot;logit&quot;),data=mydat)    # logistic regression in R
summary(model)   # summary looks similar to ordinary linear regression!</code></pre>
<pre><code>## 
## Call:
## glm(formula = response ~ predictor, family = binomial(link = &quot;logit&quot;), 
##     data = mydat)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.41677  -0.24829   0.04037   0.26223   1.97845  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -5.81957    1.37337  -4.237 2.26e-05 ***
## predictor    0.29162    0.06465   4.510 6.47e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 133.750  on 99  degrees of freedom
## Residual deviance:  49.214  on 98  degrees of freedom
## AIC: 53.214
## 
## Number of Fisher Scoring iterations: 7</code></pre>
<pre class="r"><code>newdat &lt;- data.frame(        # make predictions for plotting regression line and approx conf bounds
  predictor = seq(0,50,1)
)

mypred &lt;- predict(model,type=&quot;response&quot;,se.fit=T,newdata = newdat)

plot(response~predictor)
lines(newdat$predictor,mypred$fit,col=&quot;blue&quot;)
lines(newdat$predictor,mypred$fit+2*mypred$se.fit,col=&quot;blue&quot;,lty=2)
lines(newdat$predictor,mypred$fit-2*mypred$se.fit,col=&quot;blue&quot;,lty=2)</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Note that the relationship between the response and predictor looks
non-linear. But this is not the same thing as non-linear regression. GLM
is a type of linear model for a reason. It’s just that the relationship
is assumed to be linear on the logit scale. Here is another
visualization of the same exact model:</p>
<pre class="r"><code>par(mfcol=c(1,2))

mypred &lt;- predict(model,type=&quot;link&quot;,se.fit=T,newdata = newdat)

plot(newdat$predictor,mypred$fit,col=&quot;blue&quot;,type=&quot;l&quot;,ylab=&quot;mean response (logit scale)&quot;,xlab=&quot;predictor&quot;)
lines(newdat$predictor,mypred$fit+2*mypred$se.fit,col=&quot;blue&quot;,lty=2)
lines(newdat$predictor,mypred$fit-2*mypred$se.fit,col=&quot;blue&quot;,lty=2)


mypred &lt;- predict(model,type=&quot;response&quot;,se.fit=T,newdata = newdat)

plot(newdat$predictor,mypred$fit,col=&quot;blue&quot;,type=&quot;l&quot;,ylab=&quot;mean response&quot;,xlab=&quot;predictor&quot;)
lines(newdat$predictor,mypred$fit+2*mypred$se.fit,col=&quot;blue&quot;,lty=2)
lines(newdat$predictor,mypred$fit-2*mypred$se.fit,col=&quot;blue&quot;,lty=2)</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The standard regression diagnostic plots don’t work for logistic
regression (we’ll discuss this more in the Poisson regression example
below). However, we can use deviance residuals, Pearson residuals or
quantile residuals to assess whether the key assumptions of GLM may be
violated. I prefer to use quantile residuals, because they (unlike
deviance residuals) are useful for nearly any class of model including
logistic regression and mixed-effects models (via the DHARMa package;
see below):</p>
<pre class="r"><code> # quantile residuals (GLM diagnostics)

qr &lt;- statmod::qresiduals(model)
qqnorm(qr)
abline(0,1)</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>plot(qr~predict(model))</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
<p>One other kind of fun and useful trick is that we can use the
“equatomatic” package to display the mathematical formula for models
specified in R, including GLM models:</p>
<pre class="r"><code>## display formula!

library(equatiomatic)

equatiomatic::extract_eq(model,wrap=T,intercept = &quot;beta&quot;,show_distribution = T)</code></pre>
<p><span class="math display">\[
\begin{aligned}
\operatorname{response} &amp;\sim
Bernoulli\left(\operatorname{prob}_{\operatorname{response} =
\operatorname{1}}= \hat{P}\right) \\
\log\left[ \frac { \hat{P} }{ 1 - \hat{P} } \right]
&amp;= \beta_{0} + \beta_{1}(\operatorname{predictor})
\end{aligned}
\]</span></p>
<p>To render the equations using LaTeX, you can use something like <a
href="https://quicklatex.com/">https://quicklatex.com/</a>.</p>
</div>
<div id="another-simple-example-poisson-count-regression"
class="section level3">
<h3>Another simple example (Poisson count regression)</h3>
<p>Sometimes our measured response is a <em>count</em> of something
(e.g., number of stems in a plot). In such cases, our response variable
cannot go below zero- and the response variable should ideally come from
a discrete distribution that only allows integers. The simplest way to
model this is:</p>
<p><strong>Response distribution:</strong> Poisson<br />
<strong>Link function:</strong> Natural logarithm</p>
<p>The Poisson distribution (with only one parameter) is the simplest
discrete probability distribution, and the (natural) log is the simplest
link function that maps a quantity with a lower bound of zero to a
quantity with a lower bound of -Inf. After all, a count cannot go below
zero, whereas a linear function of predictor variables can!</p>
<p>Let’s make up some count data:</p>
<pre class="r"><code># Count regression example ------------------------------

predictor = runif(30,-2,2)
response = rnbinom(30,mu=exp(3-0.5*predictor),size=2)     # make up data!

plot(response~predictor)
abline(lm(response~predictor))</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow=c(2,2))
plot(lm(response~predictor))</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-9-2.png" width="672" /></p>
<p>Here we see some potential issues with ordinary linear regression and
we might consider Poisson count regression instead!</p>
<pre class="r"><code>## try Poisson count regression model!

mydat &lt;- mydat &lt;- data.frame(response=response,predictor=predictor)
model &lt;- glm(response~predictor,family=poisson(link=&quot;log&quot;),data=mydat)
summary(model)</code></pre>
<pre><code>## 
## Call:
## glm(formula = response ~ predictor, family = poisson(link = &quot;log&quot;), 
##     data = mydat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -7.7527  -3.1160  -0.7389   0.9276  11.2604  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  2.96492    0.04455   66.56   &lt;2e-16 ***
## predictor   -0.47449    0.03238  -14.65   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 692.54  on 29  degrees of freedom
## Residual deviance: 454.35  on 28  degrees of freedom
## AIC: 588.94
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<pre class="r"><code>plot(response~predictor,data=mydat)

newdat &lt;- data.frame(
  predictor = seq(-3,3,0.1)
)

mypred &lt;- predict(model,type=&quot;response&quot;,se.fit = T,newdata=newdat)

lines(newdat$predictor,mypred$fit,col=&quot;blue&quot;)
lines(newdat$predictor,mypred$fit+2*mypred$se.fit,col=&quot;blue&quot;,lty=2)
lines(newdat$predictor,mypred$fit-2*mypred$se.fit,col=&quot;blue&quot;,lty=2)</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>And here is the equation!</p>
<pre class="r"><code>## display formula!

library(equatiomatic)

equatiomatic::extract_eq(model,wrap=T,intercept = &quot;beta&quot;)</code></pre>
<p><span class="math display">\[
\begin{aligned}
\log ({ E( \operatorname{response} ) })  &amp;= \beta_{0} +
\beta_{1}(\operatorname{predictor})
\end{aligned}
\]</span></p>
</div>
</div>
<div id="diagnostic-testing-with-glm" class="section level2">
<h2>Diagnostic testing with GLM</h2>
<p>Obviously, the standard diagnostic plots don’t make much sense for
GLM– after all, they are testing assumptions that we are no longer
making! We don’t need to test for normality of residuals if we are
assuming our response variable is binomially distributed, or Poisson
distributed! We don’t need to test for homogeneity of variance if our
assumed probability distribution is heteroskedastic (like the Poisson
distribution)!</p>
<p>The Poisson distribution, for example, does not have homogeneous
variance- in fact, the variance of the Poisson distribution is equal to
the mean. So the larger the expected value, the larger the variance!</p>
<pre class="r"><code># Demo: heteroskedasticity in Poisson distrubution

library(tidyverse)
library(ggplot2)

thisdat &lt;- sapply(1:15,function(t) rpois(1000,lambda=t) )
thisdat &lt;- thisdat %&gt;% 
  as_tibble(.name_repair = &quot;unique&quot;) %&gt;%
  rename_with( ~str_extract(.x,pat=&quot;(\\d)+&quot;)) %&gt;% 
  pivot_longer(cols=everything(),names_to = &quot;mean&quot;, values_to = &quot;value&quot;,names_transform = as.numeric)

ggplot(thisdat,aes(x=mean,y=value)) + 
  geom_boxplot(aes(group=mean))</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>However, we need some way of testing whether the distribution we
selected is a reasonable fit to our data. We could use so-called
deviance or pearson residuals to estimate overdispersion and run other
diagnostic tests:</p>
<pre class="r"><code># test for overdispersion:

overdisp_fun &lt;- function(model) {    # function from Ben Bolker...
    rdf &lt;- df.residual(model)
    rp &lt;- residuals(model,type=&quot;pearson&quot;)
    Pearson.chisq &lt;- sum(rp^2)
    prat &lt;- Pearson.chisq/rdf
    pval &lt;- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
    list(chisq=Pearson.chisq,ratio=prat,rdf=round(rdf),p=pval)
}

options(scipen=15)
overdisp_fun(model)</code></pre>
<pre><code>## $chisq
## [1] 486.9276
## 
## $ratio
## [1] 17.39027
## 
## $rdf
## [1] 28
## 
## $p
## [1] 3.296925e-85</code></pre>
<p>Here we see that the data are overdispersed with respect to the
model- much higher variance in the data than allowed by the Poisson
distribution!</p>
<p>I prefer to use the quantile residual approach, which is very
informative across many different types of models, including GLM and
GLMM.</p>
<p>The DHARMa package in R not only implements the quantile residual
approach, but does so in a way that is applicable to nearly all models
you can fit in R!</p>
<p>NOTE: the DHARMa package also works for GLMM models (generalized
linear mixed-effects models- see below!)</p>
<pre class="r"><code> # quantile residuals (GLM diagnostics)

qr &lt;- statmod::qresiduals(model)
qqnorm(qr)
abline(0,1)

plot(qr~predict(model))</code></pre>
<p>So using the quantile residuals we’re starting to get a picture that
the Poisson distribution may not be a great fit. Let’s use the DHARMa
package now…</p>
<pre class="r"><code>library(DHARMa)

simresids &lt;- simulateResiduals(model,n=250,plot=T)   # clearly this is a bad fit!</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code>plotResiduals(simresids,predictor)   # look for patterns across a predictor variable</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-15-2.png" width="672" /></p>
<pre class="r"><code>testResiduals(simresids)  # run tests on the residuals!</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-15-3.png" width="672" /><img src="LECTURE8_files/figure-html/unnamed-chunk-15-4.png" width="672" /></p>
<pre><code>## $uniformity
## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  simulationOutput$scaledResiduals
## D = 0.38064, p-value = 0.0003355
## alternative hypothesis: two-sided
## 
## 
## $dispersion
## 
##  DHARMa nonparametric dispersion test via sd of residuals fitted vs.
##  simulated
## 
## data:  simulationOutput
## dispersion = 26.057, p-value &lt; 2.2e-16
## alternative hypothesis: two.sided
## 
## 
## $outliers
## 
##  DHARMa bootstrapped outlier test
## 
## data:  simulationOutput
## outliers at both margin(s) = 11, observations = 30, p-value &lt; 2.2e-16
## alternative hypothesis: two.sided
##  percent confidence interval:
##  0.00000000 0.05083333
## sample estimates:
## outlier frequency (expected: 0.0113333333333333 ) 
##                                         0.3666667</code></pre>
<pre><code>## $uniformity
## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  simulationOutput$scaledResiduals
## D = 0.38064, p-value = 0.0003355
## alternative hypothesis: two-sided
## 
## 
## $dispersion
## 
##  DHARMa nonparametric dispersion test via sd of residuals fitted vs.
##  simulated
## 
## data:  simulationOutput
## dispersion = 26.057, p-value &lt; 2.2e-16
## alternative hypothesis: two.sided
## 
## 
## $outliers
## 
##  DHARMa bootstrapped outlier test
## 
## data:  simulationOutput
## outliers at both margin(s) = 11, observations = 30, p-value &lt; 2.2e-16
## alternative hypothesis: two.sided
##  percent confidence interval:
##  0.00000000 0.05083333
## sample estimates:
## outlier frequency (expected: 0.0113333333333333 ) 
##                                         0.3666667</code></pre>
<p>Okay so the DHARMa package diagnostics seem to indicate that the
Poisson regression was a poor fit to the data (you will find this is
usually true with Poisson regression). Let’s try running a negative
binomial regression instead!</p>
<pre class="r"><code>## try NegBinom count regression model!

library(MASS)

## NOTE: in reality you should use glm.nb because you don&#39;t know the additional parameter theta!
model &lt;- glm(response~predictor,family=negative.binomial(link=&quot;log&quot;,theta = 2))
summary(model)</code></pre>
<pre><code>## 
## Call:
## glm(formula = response ~ predictor, family = negative.binomial(link = &quot;log&quot;, 
##     theta = 2))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.7718  -1.0497  -0.2072   0.2882   1.8582  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.9641     0.1505  19.698  &lt; 2e-16 ***
## predictor    -0.4822     0.1166  -4.135 0.000292 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(2) family taken to be 1.209932)
## 
##     Null deviance: 62.208  on 29  degrees of freedom
## Residual deviance: 41.886  on 28  degrees of freedom
## AIC: 240.81
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<pre class="r"><code>model &lt;- glm.nb(response~predictor)

plot(response~predictor)

newdat &lt;- data.frame(
  predictor = seq(-3,3,0.1)
)

mypred &lt;- predict(model,type=&quot;response&quot;,se.fit = T,newdata=newdat)

lines(newdat$predictor,mypred$fit,col=&quot;blue&quot;)
lines(newdat$predictor,mypred$fit+2*mypred$se.fit,col=&quot;blue&quot;,lty=2)
lines(newdat$predictor,mypred$fit-2*mypred$se.fit,col=&quot;blue&quot;,lty=2)</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Now let’s check the model fit!</p>
<pre class="r"><code># test goodness of fit using DHARMa!

simresids &lt;- simulateResiduals(model,n=250,plot=T)   # looks a lot better!</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre class="r"><code>testResiduals(simresids)  # run tests on the residuals!</code></pre>
<p><img src="LECTURE8_files/figure-html/unnamed-chunk-17-2.png" width="672" /><img src="LECTURE8_files/figure-html/unnamed-chunk-17-3.png" width="672" /></p>
<pre><code>## $uniformity
## 
##  Exact one-sample Kolmogorov-Smirnov test
## 
## data:  simulationOutput$scaledResiduals
## D = 0.10255, p-value = 0.879
## alternative hypothesis: two-sided
## 
## 
## $dispersion
## 
##  DHARMa nonparametric dispersion test via sd of residuals fitted vs.
##  simulated
## 
## data:  simulationOutput
## dispersion = 1.2582, p-value = 0.472
## alternative hypothesis: two.sided
## 
## 
## $outliers
## 
##  DHARMa bootstrapped outlier test
## 
## data:  simulationOutput
## outliers at both margin(s) = 0, observations = 30, p-value = 1
## alternative hypothesis: two.sided
##  percent confidence interval:
##  0.00000000 0.03333333
## sample estimates:
## outlier frequency (expected: 0.00633333333333333 ) 
##                                                  0</code></pre>
<pre><code>## $uniformity
## 
##  Exact one-sample Kolmogorov-Smirnov test
## 
## data:  simulationOutput$scaledResiduals
## D = 0.10255, p-value = 0.879
## alternative hypothesis: two-sided
## 
## 
## $dispersion
## 
##  DHARMa nonparametric dispersion test via sd of residuals fitted vs.
##  simulated
## 
## data:  simulationOutput
## dispersion = 1.2582, p-value = 0.472
## alternative hypothesis: two.sided
## 
## 
## $outliers
## 
##  DHARMa bootstrapped outlier test
## 
## data:  simulationOutput
## outliers at both margin(s) = 0, observations = 30, p-value = 1
## alternative hypothesis: two.sided
##  percent confidence interval:
##  0.00000000 0.03333333
## sample estimates:
## outlier frequency (expected: 0.00633333333333333 ) 
##                                                  0</code></pre>
<p>And this time our count regression model fits the data well, and we
can report the results of this model with confidence!</p>
<p>NOTE: you should always run goodness-of-fit tests for any model you
fit to data. But it is especially important in the case of Poisson
regression, because in general most count data has much more variance
that a Poisson distribution allows for (and sometimes it has less..).
This can lead to a host of problems- included inflated “significance” of
your effects). You should always be wary of reported Poisson regression
results with no goodness of fit checks!</p>
</div>
<div id="model-selection-with-aic" class="section level2">
<h2>Model selection with AIC</h2>
<p>Often we have multiple <strong>candidate models</strong> for
describing how our response variable relates to one or more of our
predictor variables. This is true for multiple linear regression and GLM
models, and mixed-effects models (see below) and non-linear regression
models.</p>
<p>Information-theoretic criteria like <strong>Akaike’s Information
Criterion</strong> provide a common currency that allows us to compare
and rank multiple models.</p>
<p>In general, the models with the lowest AIC are better than models
with higher AIC.</p>
<p>AIC is defined as:</p>
<p><span class="math inline">\(AIC = -2\cdot ln(Likelihood) + 2\cdot
k\)</span></p>
<p>Where <em>k</em> is the number of fitted parameters in the model and
<em>Likelihood</em> is the maximum likelihood of the data (probability
of the observed data set under the fitted model).</p>
<p>There is a commonly used correction for small sample size called
<em>AICc</em>:</p>
<p><span class="math inline">\(AICc = AIC +
\frac{2k^2+2k}{n-k-1}\)</span></p>
<p>Comparing multiple GLM models using AIC is relatively simple!</p>
<pre class="r"><code># AIC model selection ----------------------

# Make up data!

predictor1 = runif(30,-2,2)
predictor2 &lt;- runif(30,-100,100)
predictor3 &lt;- rnorm(30)   # useless predictor
response = rnbinom(30,mu=exp(3-0.5*predictor1+0.01*predictor2),size=2)

# fit a bunch of candidate models

model.pois.all &lt;- glm(response~predictor1+predictor2+predictor3,family=&quot;poisson&quot;)
model.nb.all &lt;- glm.nb(response~predictor1+predictor2+predictor3)
model.nb.1 &lt;- glm.nb(response~predictor1)
model.nb.12 &lt;- glm.nb(response~predictor1+predictor2)
model.nb.2 &lt;- glm.nb(response~predictor2)

cand.set &lt;- list(
  Poisson=model.pois.all,
  NegBin_allvars = model.nb.all,
  NegBin_pred1 = model.nb.2,
  NegBin_preds1and2 = model.nb.12,
  NegBin_pred2 = model.nb.2
)

### Make AIC table

AICtab &lt;- data.frame(
  ModelName = names(cand.set),
  LogLikelihood = sapply(cand.set,logLik),
  AIC = sapply(cand.set,AIC)
)

k &lt;- c(3,3,1,2,1)
AICtab$AICc &lt;- AICtab$AIC + (2*k^2+2*k)/(30-k-1)

AICtab$DeltaAICc &lt;- abs(AICtab$AICc-min(AICtab$AICc))

AICtab[order(AICtab$DeltaAICc,decreasing = F),]</code></pre>
<pre><code>##                           ModelName LogLikelihood      AIC     AICc  DeltaAICc
## NegBin_allvars       NegBin_allvars     -121.8939 253.7877 254.7108   0.000000
## NegBin_preds1and2 NegBin_preds1and2     -124.1918 256.3836 256.8280   2.117221
## NegBin_pred1           NegBin_pred1     -130.4119 266.8238 266.9667  12.255908
## NegBin_pred2           NegBin_pred2     -130.4119 266.8238 266.9667  12.255908
## Poisson                     Poisson     -322.9859 653.9718 654.8949 400.184078</code></pre>
<p>NOTE: for AIC model comparison to make sense, the response variable
must be exactly the same (note: you can’t compare different
transformations of the response variable) and the number of observations
must be exactly the same. Careful with missing data here!</p>
<p><a href="LECTURE9.html">–go to next lecture–</a></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
