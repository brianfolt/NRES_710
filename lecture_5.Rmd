---
title: "Linear Regression - presenting results"
author: "NRES 710"
date: "Last compiled: `r Sys.Date()`"
output: 
  html_document: 
    theme: yeti
    toc: yes
    toc_float: yes
    css: styles.css
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	cache = TRUE
)
```

```{r echo=FALSE}

#  NRES 710, Linear Regression 2 
#     University of Nevada, Reno
#     Presenting results of linear regression   

```

## Review

Today we will discuss how to present results from linear regression. I am going to describe an approach that uses a few concise sentences to distill down all of the relevant information from the analysis you ran. But first, a brief review from last class.

**The equation for the general linear model: $Y = \beta0 + \beta1X + \epsilon \sim N(0, \sigma)$**

- We will use this throughout the class!
- Y is equal to beta0 (intercept) plus beta1 (slope) times X plus error, which is normally distributed with a mean of zero and a standard deviation (sigma).
- The error term indicates that we have a bunch of noise that is centered on the line (mean of zero), standard deviation has to be estimated and determines how close to the line the points are.
- We determine this lining by ensuring the average error is zero and minimize the sum of squares error (the distance from every point to that line).
- To calculate p-values, we partition the total variation in Y (Total Sum of Squares; TSS) into Sum of Squared Error (SSE) and the Sum of Squares due to Regression (SSR). **TSS = SSE + SSR.**
- Three things that influence p-values in regression: sample size, effect size, and noise.

## Presenting results from regression

Today we will discuss how to report results when you run regression. By spending time discussing how to report the results, I am hoping this will help all of the material in this class make more sense.

In class exercise, I will expect you to report your results using this format, which is the format that you would be expected to report results in your thesis, dissertation, and scientific papers that you publish. This approach has **four elements**:

1) **Slope**
2) **P-value** (And you should report a slope whether or not the p-value is significant or not!)
3) **Confidence interval**
4) **$r^2$**

We have discussed slopes and p-values in the previous few classes, but today we will introduce confidence intervals and $r^2$ values at greater detail.

## Confidence intervals

**95% confidence intervals (95% CI) -- a measure of uncertainty** around our estimate

- Often, **95% CI ~ 2 * SE**, although the exact formula depends on the sample size.

- We have given our reader an estimate of the p-value, but it is unlikely to be a perfect estimate of truth.
- On average, it is unbiased. If we collect some data 1,000 different times and fit a regression each time, the average slope from among each of those regressions will approximate truth. But any one regression on a single dataset may not be very close to truth... due to the nature of data, noise, process error, and sampling error.
- Thus, we need to give our readers some measure of how certain we think our slope really is.

Definition of 95% confidence interval: **95% of all such intervals contain truth.**

- It might be tempting to think about CI by saying that: there's a 95% chance that truth is within the interval.
- However, this is **wrong**, because of the idea of the coinflip from the first day of class. Truth is either inside the interval, or it isn't. Just because we don't know that does not mean there is an underlying probability.
- This is a nice way of thinking about confidence intervals, but it's not technically correct.
- Does this make sense? I personally find this topic confusing.

Here's how we might visualize this. I simulated 100 random datasets, each with a mean $\mu$ = 5, and then I measured the mean and 95% confidence intervals for each of the 100 datasets. I then plotted each individual datasets on the y-axis (1 to 100) and the 95% confidence intervals around the mean on the x-axis.

```{r simulate-ci-plot, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=7}
# Set the seed for reproducibility
set.seed(123)

# Parameters
mu <- 5
n_simulations <- 100
n_samples <- 30
alpha <- 0.05

# Function to calculate 95% CI
calculate_ci <- function(data, alpha) {
  mean_val <- mean(data)
  se <- sd(data) / sqrt(length(data))
  error <- qt(1 - alpha/2, df=length(data) - 1) * se
  ci_lower <- mean_val - error
  ci_upper <- mean_val + error
  return(c(ci_lower, ci_upper))
}

# Simulate data and calculate CIs
ci_list <- matrix(NA, nrow=n_simulations, ncol=2)
for (i in 1:n_simulations) {
  sample_data <- rnorm(n_samples, mean=mu, sd=1)
  ci_list[i, ] <- calculate_ci(sample_data, alpha)
}

# Create a data frame for plotting
ci_df <- data.frame(
  Sample = 1:n_simulations,
  CI_Lower = ci_list[, 1],
  CI_Upper = ci_list[, 2],
  Contains_Mu = (ci_list[, 1] <= mu & ci_list[, 2] >= mu)
)

# Plotting the CIs
library(ggplot2)
ggplot(ci_df, aes(y = Sample, x = CI_Lower, xend = CI_Upper)) +
  geom_segment(aes(yend = Sample, color = Contains_Mu), size = 1.2) +
  scale_color_manual(values = c("TRUE" = "black", "FALSE" = "red")) +
  geom_vline(xintercept = mu, linetype = "dashed") +
  labs(x = "Confidence Interval",
       y = "Sample Number",
       color = "Contains Mean") +
  theme_minimal() +
  theme(legend.position = "top")

```

The red intervals are situations where the 95% confidence intervals do not include the true known mean!

Unfortunately, we have no idea if our particular confidence interval is one that includes 'truth' for the parameter!

Don't worry if you find this difficult -- I think most people do! And practically speaking, just about everyone interprets a 95% confidence interval as having a 95% probability of including the true parameter -- and it doesn't really matter that much!

### 95% CI and significance testing

Here's another useful way to think about this *graphically*.

Let's create a frequency distribution (y-axis) of our slope (x-axis). We run 1000 regressions, and get 1000 estimates of slope. The mean of all these estimates is 'truth' -- the true slope. The distribution of estimates would be a normally-distributed bell curve. A noisy system has a wide bell curve and a wide confidence interval; a less noisy system (or a large sample sizes) would have a more narrow confidence interval. See below:

```{r normal-curve-plot-base-r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5, fig.height=4.5}
# Set parameters for the normal distribution
mean_slope <- 0  # Mean labeled as "Slope"
sd_slope <- 1    # Standard deviation

# Create a sequence of x values
x_values <- seq(mean_slope - 4 * sd_slope, mean_slope + 4 * sd_slope, length.out = 1000)

# Calculate the density values and normalize them
density_values <- dnorm(x_values, mean = mean_slope, sd = sd_slope)
density_values_less_noisy <- dnorm(x_values, mean = mean_slope, sd = sd_slope / 2)

# Normalize the density values so that their peaks are the same
density_values <- density_values / max(density_values)
density_values_less_noisy <- density_values_less_noisy / max(density_values_less_noisy)

# Reduce outer margins
par(mar = c(4, 6, 0, 0), mgp = c(2, 0.5, 0))  # bottom, left, top, right

# Plot the normal distribution
plot(x_values, density_values, type = "l", col = "blue", lwd = 4,
     xlab = expression("True slope (or " * beta[1] * ")"), ylab = "Frequency", cex.lab = 1.5,
     ylim = c(0, 1.1), axes = FALSE)

# Add the second normal distribution
lines(x_values, density_values_less_noisy, col = "green", lwd = 4)

# Add vertical line for the mean
abline(v = mean_slope, lty = 2, lwd = 4, col = "orange")

# Add box around the plot
box()

# Add legend
legend("topright", legend = c("Noisy data", "Less noisy data"), 
       col = c("blue", "green"), lwd = 2, bty = "n", cex = 1.2)
```

The confidence interval in our regression takes this distribution and instead of centering it on 'truth', it centers it on our estimated slope ($\beta_1$). If we assume this is the true slope, this bell curve represents the range of $\beta_1$ estimates we would get when we run regression.

95% of the time we will get a slope estimate that is within the central area under the curve that contains 95% of this distribution. This is the 95% confidence interval. We can add two lines to the above graph to indicate this range of values around the true slope:

```{r normal-curve-2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5, fig.height=4.5}
# Set parameters for the normal distribution
mean_slope <- 0  # Mean labeled as "Slope"
sd_slope <- 1    # Standard deviation
ci_level <- 0.95  # Confidence level

# Calculate the 95% CI boundaries
z_score <- qnorm((1 + ci_level) / 2)
ci_lower <- mean_slope - z_score * sd_slope
ci_upper <- mean_slope + z_score * sd_slope

# Create a sequence of x values
x_values <- seq(mean_slope - 4 * sd_slope, mean_slope + 4 * sd_slope, length.out = 1000)

# Calculate the density values and normalize them
density_values <- dnorm(x_values, mean = mean_slope, sd = sd_slope)

# Normalize the density values so that their peaks are the same
density_values <- density_values / max(density_values)

# Reduce outer margins
par(mar = c(4, 6, 0, 0), mgp = c(2, 0.5, 0))  # bottom, left, top, right

# Plot the normal distribution
plot(x_values, density_values, type = "l", col = "blue", lwd = 4,
     xlab = expression("True slope"), ylab = "Frequency", cex.lab = 1.5,
     ylim = c(0, 1.1), axes = FALSE)

# Add vertical line for the mean
abline(v = mean_slope, lty = 2, lwd = 4, col = "orange")

# Add vertical lines for the 95% CI
abline(v = ci_lower, col = "purple", lwd = 2, lty = 2)
abline(v = ci_upper, col = "purple", lwd = 2, lty = 2)

# Add box around the plot
box()

# Add legend
legend("topright", legend = c("Data", "Mean", "95% CI"), 
       col = c("blue", "orange", "purple"), lwd = 4, lty = c(1, 2, 2), bty = "n", cex = 1.2)
```

This same bell curve is also used in the calculation of **p-values**. Instead of centering on slope of mean = 'truth', it centers the distribution on a slope = 0, and it says: if we assume that slope = 0 (the null hypothesis; $H_0$), what is the probability of getting our observed data that produced $\beta_1$?

```{r normal-curve-3, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5, fig.height=4.5}
# Set parameters for the normal distribution
mean_slope <- 0  # Mean labeled as "Slope"
sd_slope <- 1    # Standard deviation
ci_level <- 0.95  # Confidence level

# Calculate the 95% CI boundaries
z_score <- qnorm((1 + ci_level) / 2)
ci_lower <- mean_slope - z_score * sd_slope
ci_upper <- mean_slope + z_score * sd_slope

# Create a sequence of x values
x_values <- seq(mean_slope - 4 * sd_slope, mean_slope + 4 * sd_slope, length.out = 1000)

# Calculate the density values and normalize them
density_values <- dnorm(x_values, mean = mean_slope, sd = sd_slope)

# Normalize the density values so that their peaks are the same
density_values <- density_values / max(density_values)

# Reduce outer margins
par(mar = c(4, 6, 0, 0), mgp = c(2, 0.5, 0))  # bottom, left, top, right

# Plot the normal distribution
plot(x_values, density_values, type = "l", col = "blue", lwd = 4,
     xlab = expression("Slope = 0 (" * H[0] * ")"), ylab = "Frequency", cex.lab = 1.5,
     ylim = c(0, 1.1), axes = FALSE)

# Add vertical line for the mean
abline(v = mean_slope, lty = 2, lwd = 4, col = "orange")

# Add vertical lines for the 95% CI
abline(v = ci_lower, col = "purple", lwd = 2, lty = 2)
abline(v = ci_upper, col = "purple", lwd = 2, lty = 2)

# Add a dot in the bottom right tail and label it as "Beta1"
dot_x <- mean_slope + 2.4 * sd_slope  # Position of the dot
dot_y <- dnorm(dot_x, mean = mean_slope, sd = sd_slope) / max(density_values) * 0.1  # Adjust y position
points(dot_x, dot_y, pch = 19, col = "red", cex = 1.5)
text(dot_x, dot_y, labels = expression(beta[1]), pos = 2, col = "red", cex = 1.2)

# Add box around the plot
box()

# Add legend
legend("topright", legend = c("Data", "Mean", "95% CI"), 
       col = c("blue", "orange", "purple"), lwd = 4, lty = c(1, 2, 2), bty = "n", cex = 1.2)
```

If our $\beta_1$ is out in the tail of this distribution (or, outside of the 95% confidence interval), then we would get a small p-value, and then **reject** $H_0$.

**What this means is that we technically don't need a p-value!** Our confidence interval can tell us whether our slope estimate is statistically significant or not.

All we need to know is whether 0 (zero) is within the 95% confidence interval of $\beta$ or not.

```{r normal-curve-4, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5, fig.height=4.5}
# Set parameters for the normal distribution
mean_slope <- 0  # Mean labeled as "Slope"
sd_slope <- 1    # Standard deviation
ci_level <- 0.95  # Confidence level

# Calculate the 95% CI boundaries
z_score <- qnorm((1 + ci_level) / 2)
ci_lower <- mean_slope - z_score * sd_slope
ci_upper <- mean_slope + z_score * sd_slope

# Create a sequence of x values
x_values <- seq(mean_slope - 4 * sd_slope, mean_slope + 4 * sd_slope, length.out = 1000)

# Calculate the density values and normalize them
density_values <- dnorm(x_values, mean = mean_slope, sd = sd_slope)

# Normalize the density values so that their peaks are the same
density_values <- density_values / max(density_values)

# Reduce outer margins
par(mar = c(4, 6, 0, 0), mgp = c(2, 0.5, 0))  # bottom, left, top, right

# Plot the normal distribution
plot(x_values, density_values, type = "l", col = "blue", lwd = 4,
     xlab = expression(beta[1]), ylab = "Frequency", cex.lab = 1.5,
     ylim = c(0, 1.1), axes = FALSE)

# Add vertical line for the mean
abline(v = mean_slope, lty = 2, lwd = 4, col = "orange")

# Add vertical lines for the 95% CI
abline(v = ci_lower, col = "purple", lwd = 2, lty = 2)
abline(v = ci_upper, col = "purple", lwd = 2, lty = 2)

#  Add vertical line to the right of the 95% CI and label it zero
zero_line <- ci_lower - 1.5
abline(v = zero_line, col = "red", lwd = 2, lty = 1)

# Add x-axis with a single tick for zero
axis(1, at = -3.46, labels = "0", las = 1)

# Add box around the plot
box()

# Add legend
legend("topright", legend = c("Data", "Mean", "95% CI", "Zero"), 
       col = c("blue", "orange", "purple", "red"), lwd = 4, lty = c(1, 2, 2, 1), bty = "n", cex = 1.2)

```

- If 0 is **outside** the 95% CI for $\beta$, then $\beta$ **is** a real, statistically significant effect!
- If 0 is **inside** the 95% CI for $\beta$, then $\beta$ **is not** a real, statistically significant effect.

Confidence interval terms:

- **Confidence limits:** the values for the upper and lower edges of 95% CI.
- **Confidence interval:** the distance between the $\beta$ and each confidence limit.

If we get a p-value = 0.05, that means zero will be at one of our confidence limits (i.e., significant).

If we zero is outside of our confidence limits, the p-value will be < 0.05 (i.e., significant).

If zero is within one of our confidence limits, the p-value will be > 0.5 (i.e., not significant).

### Reporting confidence intervals

**$\beta_1$ +/- 95% CI**

Since the CI are symmetric, we can use plus/minus to report the CI.

- Note: why use +/i? Journals made this rule up to save space...

### What you need to know:

1. The technical definition of a 95% confidence interval: 95% of all such intervals contain 'truth'.
2. The relationship between confidence intervals and p-values. They are the flip-side of the same coin.

Easy red flag: something is significant, but the 95% CI include zero.

## $r^2$

### What is $r^2$

The technical definition of **$r^2$ is the *proportion* of variation in Y that is explained by X.** This definition will be on quizes, etc. Keyword: *proportion*.

- This is **not** the absolute amount of variation in Y explained by X -- which is the Sum of Squares due to Regression (SSR).
- How do you estimate the *proportion*...? Divide by the TOTAL.. the Total Sum of Squares (TSS).
- Also known as: coefficient of determination.

**Thus: $r^2 = \frac{SSR}{TSS}$**

Since it is a proportion, 0 < $r^2$ < 1.

If $r^2$ = 0, then no variation in Y is explained by X, and the slope is zero. Points at random, with no slope.

If $r^2$ = 1, then all variation in Y is explained by X -- and no variation in Y is due to error. All your points are right on the line!

This doesn't really ever happen in environmental sciences... There is so much noise and other processes driving relationpships that $r^2$ values never approach 1! Some have said that an $r^2$ of 0.1 is a good results in ecology (!).

**r** is the **correlation coefficient**

- $r = \sqrt{r^2}$
- This can be positive or negative and anywhere from -1 to 1; it can describe negative relationships or positive relationships.

### Why report $r^2$?

Why report $r^2$, when I have previously said the main goal of regression was to measure the slope...?

Let's assume you graduate and get a job as a habitat manager. Your new supervisor wants you to increase Greater Sage-grouse density in central Nevada, and they want you to do it by manipulating some variable (e.g, native grass density). You go out and collect data to estimate the relationship between grouse and grasses. Which of the following two scenarios would you rather have?

```{r simulate-plot-4, echo=FALSE, message=FALSE, warning=FALSE, fig.width=9, fig.height=4}
# Set the seed for reproducibility
set.seed(123)

# Set up the plotting area to display two plots side by side
par(mfrow = c(1, 2))

# Simulate data for the shallow slope
n <- 40
x1 <- rnorm(n, mean = 20, sd = 10)
y1 <- round(10 + 3 * x1 + rnorm(n, mean = 0, sd = 16), 1)

# Create a data frame for the shallow slope
datum1 <- data.frame(x = x1, y = y1)

# Plot the data with the shallow slope
plot(y ~ x, data = datum1,
     ylim=c(0, 100), xlab = "Grass density", ylab = "Grouse abundance")

# Add a line to the plot for the shallow slope
results1 <- lm(y ~ x, data = datum1)
abline(results1)

# Simulate data for the steep slope
x2 <- rnorm(n, mean = 20, sd = 10)
y2 <- round(10 + 1 * x2 + rnorm(n, mean = 0, sd = 2), 1)

# Create a data frame for the steep slope
datum2 <- data.frame(x = x2, y = y2)

# Plot the data with the steep slope
plot(y ~ x, data = datum2,
     ylim=c(0, 100), xlab = "Grass density", ylab = "Grouse abundance")

# Add a line to the plot for the steep slope
results2 <- lm(y ~ x, data = datum2)
abline(results2)
```

Left graph has a steeper slope, but right graph has less error.

**Q:** Anybody want to make an argument for the left situation being better?

- Left graph: a small change in X makes a larger increase in Y, because the effect size is big.

**Q:** Anybody want to make an argument for the right situation being better?

- Right graph: we may have to make a bigger change in X to make the same change in Y, but we **know** that we will achieve that change in Y. 

- Left graph: There is a lot of uncertainty, and an increase in X could actually cause a decreased outcome in Y.

It's not enough to report the slope... we can also benefit from reporting $r^2$ because it **describes the strength of the relationship and how closely X and Y are related.**

## Reporting results

**For each 1 [X-units] increase in [X], we observed a [slope / $\beta_1$] [Y-units] (+/- [95% CI]; +/- 95% CI) [increase/decrease] in [Y] (p = [p-value]; [$r^2$]).**

**If p > 0.05, then add: "; however, our results are not statistically significant."**

Let's try this with our results from last class.

```{r regression_example, echo=TRUE, message=FALSE, warning=FALSE}
# Set the seed for reproducibility
set.seed(123)

# Simulate a continuous predictor variable, precipitation
n <- 30
precip <- runif(n, min = 0, max = 10)

# Simulate the true, predicted response of biomass to precip (y-hat)
y_hat <- 2 + 3 * precip

# Simulate error for the response variable
error <- rnorm(n, mean = 0, sd = 2)

# Create the response variable, biomass
# biomass = beta0 + beta1 * precip + epsilon
biomass <- y_hat + error

# Create a data frame
datum <- data.frame(precip = precip, y_hat = y_hat, error = error, biomass = biomass)

# Fit the linear model
results <- lm(biomass ~ precip, data = datum)

# Examine the results
summary(results)

# Print the confidence intervals
confint(results)
# These are actually the confidence limits! Annoying
# How do we calculate the confidence intervals
```

**For each 1 cm increase in precipitation, we observed a 2.81 kg/ha ...** -- but where are the confidence intervals??

**Note:** I recommend simply using two significant digits after the decimal. In the above case, you would avoid saying "a 3 unit increase" or "a 2.8 unit increase".

- (Sidenote: technically, usual scientific convention involved reporting significant digits according to precision in the sampling... Maybe you remember this from chemistry class? But we often don't know that in ecology, so we can be more relaxed about this here.)

```{r regression_example_2, echo=TRUE, message=FALSE, warning=FALSE}
# Print the confidence intervals
confint(results)
# These are actually the confidence limits! Annoying
```

These are actually the confidence limits! This is annoying.

**Q:** How would we calculate the 95% CI? There are a few ways...

- 1) Upper limit minus estimate
- 2) Estimate minus lower limit
- 3) Upper limit minus lower limit divided by two
- Use whichever one makes most sense to you. I frequently use (3), but don't forget to divide by two! Also, be careful with negative values...

```{r regression_example_3, echo=TRUE, message=FALSE, warning=FALSE}
(3.071 - 2.556) / 2
3.071 - 2.814
```

**For each 1 cm increase in precipitation, we observed a 2.81 kg/ha (+/-0.25; 95% CI) increase in biomass, which was statistically significant (p < 2x10^-16; $r^2$ = 0.95).**

95% of the variation is explained by precipitation, while 5% is driven by noise!

Notes:

- When p < 2x10^-16, the p-value is so small that Program R won't even give you the exact value.
- Report the exact p-value with scientific notation in this class.
- Two $r^2$ values! Generally, we want to always use the multiple $r^2$ -- ignore the adjusted. $r^2$ values often go up when we add more variables, and the adjusted $r^2$ tries to account for that. We may talk about this later, but just use the 'Multiple r-sqared' value.

### Minor adjustments

**Q:** What if the effect (slope) is negative? Don't include the negative in the sentence, just change **increase to decrease**.

Sometimes when the way we measure things makes our $\beta$ values a little... strange. For example, elevational gradients influence species richness in strong ways. However, the unit change for elevation is meters (meter), and a 1 unit increase in meters will only have a tiny effect on species richness -- although highly significant. We can **re-scale** the metrics at ecologically relevant scales to make the effects make more sense. For elevation, we might multiple the X value, the effect, and the 95% CI times 1000, so that everything is expressed in terms of kilometers, rather than meters. You can do this with your raw data or with your results.

When you are trying to compare two different effects and trying to infer which has a stronger biological effect, you cannot compare one beta to another. 

- Which is more important in driving biomass: precipitation or fertilizer?
- We can't make that comparison.
- If you want to compare betas directly, you have to standardize your variables first, before fitting the model.
  - 'Mean transformation': subtract each value by the mean and divide by the standard deviation.

## Concluding thoughts

I really like this sentence structure for reporting results. This was what I was taught in graduate school, and I have taught this to many peers and students since then. I find that it makes clear sense to readers about cause and effect in ecology. You could read this to your dad and they will understand it. They may not care -- but they would understand it. That's powerful!

**We want to communicate our science clearly to our scientific peers, natural resource managers, and policy makers, and the public.** This sentence structure is useful to do this. It is clear and it emphasizes biological effects, which helps us better understand and communicate cause and effect in nature.

This sentences are what you will report for the results of your exercise on linear regression! That's it -- report these sentences. I will not check your exact grammar, but it should follow this general pattern and be mindful of some of the details I mentioned above.

[--go to next lecture--](lecture_6.html)
